{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fceaef71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastai in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (2.8.2)\n",
      "Requirement already satisfied: pip in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from fastai) (25.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from fastai) (24.2)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from fastai) (0.0.7)\n",
      "Requirement already satisfied: fastcore<1.9,>=1.8.0 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from fastai) (1.8.7)\n",
      "Requirement already satisfied: fasttransform>=0.0.2 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from fastai) (0.0.2)\n",
      "Requirement already satisfied: torchvision>=0.11 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from fastai) (0.22.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from fastai) (3.10.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from fastai) (2.2.3)\n",
      "Requirement already satisfied: requests in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from fastai) (2.32.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from fastai) (6.0.2)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from fastai) (1.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from fastai) (11.1.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from fastai) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from fastai) (1.15.1)\n",
      "Requirement already satisfied: spacy<4 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from fastai) (3.8.7)\n",
      "Requirement already satisfied: plum-dispatch in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from fastai) (2.5.7)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from fastai) (3.0.0)\n",
      "Requirement already satisfied: torch<2.8,>=1.10 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from fastai) (2.7.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from spacy<4->fastai) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from spacy<4->fastai) (2.2.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from spacy<4->fastai) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from spacy<4->fastai) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from spacy<4->fastai) (76.1.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from requests->fastai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from requests->fastai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from requests->fastai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from requests->fastai) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai) (0.1.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from torch<2.8,>=1.10->fastai) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from torch<2.8,>=1.10->fastai) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from torch<2.8,>=1.10->fastai) (3.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from torch<2.8,>=1.10->fastai) (2025.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<4->fastai) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (8.1.8)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4->fastai) (1.17.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch<2.8,>=1.10->fastai) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->spacy<4->fastai) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->fastai) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->fastai) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->fastai) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->fastai) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->fastai) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->fastai) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from pandas->fastai) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from pandas->fastai) (2025.1)\n",
      "Requirement already satisfied: beartype>=0.16.2 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from plum-dispatch->fastai) (0.21.0)\n",
      "Requirement already satisfied: rich>=10.0 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from plum-dispatch->fastai) (13.9.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from rich>=10.0->plum-dispatch->fastai) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from rich>=10.0->plum-dispatch->fastai) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.0->plum-dispatch->fastai) (0.1.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn->fastai) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn->fastai) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be63294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastcore.parallel import *\n",
    "import fastai\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d46cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in c:\\users\\yashwanth\\anaconda3\\lib\\site-packages (1.0.19)\n",
      "Requirement already satisfied: torch in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from timm) (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from timm) (0.22.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from timm) (0.33.1)\n",
      "Requirement already satisfied: safetensors in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from huggingface_hub->timm) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from huggingface_hub->timm) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from huggingface_hub->timm) (24.2)\n",
      "Requirement already satisfied: requests in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from huggingface_hub->timm) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from torch->timm) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from torch->timm) (76.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from torchvision->timm) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\yashwanth\\appdata\\roaming\\python\\python313\\site-packages (from torchvision->timm) (11.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780f1a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "#model = timm.create_model(\"efficientformerv2_s2\", pretrained=True)\n",
    "#torch.save(model.state_dict(), \"efficientformerv2_s2_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "728d0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path =Path(\"C:/Users/Yashwanth/isic/train-metadata.csv\")\n",
    " \n",
    "hdf5_file=Path('C:/Users/Yashwanth/isic/train-image.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0fd5107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yashwanth\\AppData\\Local\\Temp\\ipykernel_26960\\301825288.py:1: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(metadata_path)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b304af4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab858921",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_cat_columns = ['sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdb874d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specified columns\n",
    "columns_to_drop = ['copyright_license', 'attribution', 'image_type', 'iddx_1', 'iddx_2', 'iddx_3', 'iddx_4',\n",
    "                   'iddx_5', 'iddx_full', 'mel_mitotic_index', 'mel_thick_mm', 'tbp_tile_type', \n",
    "                   'tbp_lv_dnn_lesion_confidence', 'lesion_id']\n",
    "\n",
    "# Define categorical columns manually (based on what you likely intended)\n",
    "cat_names = ['sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple']\n",
    "\n",
    "# Manually set new_cat_columns (fallback because CSV is missing)\n",
    "new_cat_columns = cat_names  # You can edit or expand this list later if needed\n",
    "\n",
    "# Define continuous columns (all columns not in categorical or dropped list)\n",
    "cont_names = [x for x in df.columns if x not in (cat_names + ['target', 'isic_id', 'patient_id'] + columns_to_drop)]\n",
    "\n",
    "# Define the target and image ID columns\n",
    "y_col = 'target'\n",
    "image_col = 'isic_id'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b04860",
   "metadata": {},
   "source": [
    "# Create a custom dataset that includes both image and tabular data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "230b28bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports for custom dataset class\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Define the ImageTabDataset class to combine image + tabular data\n",
    "class ImageTabDataset(Dataset):\n",
    "    def __init__(self, df, hdf5_file, cat_cols, cont_cols, target_col, img_key='image_id'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.hdf5 = h5py.File(hdf5_file, 'r')\n",
    "        self.cat_cols = cat_cols\n",
    "        self.cont_cols = cont_cols\n",
    "        self.target_col = target_col\n",
    "        self.img_key = img_key\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load image from HDF5 using the image ID\n",
    "        img_id = str(row[self.img_key])\n",
    "        img = self.hdf5[img_id][()]  # shape: (C, H, W) expected\n",
    "        img = torch.tensor(img, dtype=torch.float32)\n",
    "\n",
    "        # Extract categorical and continuous variables\n",
    "        cat_values = torch.tensor(row[self.cat_cols].values, dtype=torch.long)\n",
    "        cont_values = torch.tensor(row[self.cont_cols].values, dtype=torch.float32)\n",
    "\n",
    "        # Extract the label\n",
    "        label = torch.tensor(row[self.target_col], dtype=torch.long)\n",
    "\n",
    "        return img, cat_values, cont_values, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9db3a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries: PyTorch, FastAI, Sklearn, and others\n",
    "import h5py\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from fastai.tabular.all import TabularPandas, get_emb_sz, TabularModel, Learner, CrossEntropyLossFlat, accuracy\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "\n",
    "# Set up the device to use GPU if available; otherwise, fallback to CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# --- Stratified Train-Validation Split ---\n",
    "\n",
    "# Custom function to split the dataset into training and validation sets \n",
    "# while preserving the original class distribution\n",
    "def stratified_splitter(df, valid_pct=0.25, seed=42):\n",
    "    train_indices, valid_indices = train_test_split(\n",
    "        df.index,\n",
    "        test_size=valid_pct,\n",
    "        stratify=df[y_col],  # Ensures class distribution remains balanced\n",
    "        random_state=seed\n",
    "    )\n",
    "    return train_indices, valid_indices\n",
    "\n",
    "# Applying the stratified split function on the dataset\n",
    "train_indices, valid_indices = stratified_splitter(df)\n",
    "\n",
    "# Extract the actual training and validation DataFrames using the indices\n",
    "train_df = df.iloc[train_indices]\n",
    "valid_df = df.iloc[valid_indices]\n",
    "\n",
    "# --- Dataset and DataLoader Preparation ---\n",
    "\n",
    "# Wrap tabular + image data into custom PyTorch datasets\n",
    "train_dataset = ImageTabDataset(train_df, hdf5_file, new_cat_columns, cont_names, y_col)\n",
    "valid_dataset = ImageTabDataset(valid_df, hdf5_file, new_cat_columns, cont_names, y_col)\n",
    "\n",
    "# Load data into PyTorch's DataLoader for efficient batch processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# Combine the two DataLoaders into one object for use in FastAI\n",
    "dls = DataLoaders(train_loader, valid_loader)\n",
    "\n",
    "# --- Tabular Embedding Sizes ---\n",
    "\n",
    "# This helper function calculates the embedding sizes required \n",
    "# for each categorical variable based on its number of unique values\n",
    "def get_emb_szs(df, new_cat_columns):\n",
    "    return [(df[col].nunique() + 1, min(50, (df[col].nunique() + 1) // 2)) for col in new_cat_columns]\n",
    "\n",
    "# Calculate the required embedding sizes for the categorical columns\n",
    "emb_szs = get_emb_szs(train_df, new_cat_columns)\n",
    "\n",
    "# Count the number of continuous features in the dataset\n",
    "n_cont = len(cont_names)\n",
    "\n",
    "# Determine the number of target classes in the dataset\n",
    "out_sz = len(train_df[y_col].unique())\n",
    "\n",
    "# --- Custom Neural Network Models ---\n",
    "\n",
    "# Model 1: Combines a frozen ResNet50 CNN for image features \n",
    "# and a tabular neural network for structured data\n",
    "class ImageTabularModel_1(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, ps=0.5):\n",
    "        super().__init__()\n",
    "        # Load a pretrained ResNet50 model\n",
    "        self.cnn = models.resnet50(weights=None)\n",
    "        self.cnn.load_state_dict(torch.load('resnet50-11ad3fa6.pth'))\n",
    "\n",
    "        \n",
    "        # Freeze all layers except the final one\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False\n",
    "        num_ftrs = self.cnn.fc.in_features\n",
    "        self.cnn.fc = nn.Linear(num_ftrs, out_sz)\n",
    "        for param in self.cnn.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # Define the tabular (structured) model\n",
    "        self.tab_net = TabularModel(emb_szs, n_cont, out_sz, layers, ps)\n",
    "        \n",
    "        # Combine both models’ outputs before final prediction\n",
    "        self.head = nn.Linear(out_sz * 2, out_sz)\n",
    "\n",
    "    def forward(self, x_img, x_cat, x_cont):\n",
    "        # Convert categorical data to long format if needed\n",
    "        if x_cat.dtype != torch.long:\n",
    "            x_cat = x_cat.long()\n",
    "\n",
    "        # Get features from both the CNN and tabular network\n",
    "        img_out = self.cnn(x_img)\n",
    "        tab_out = self.tab_net(x_cat, x_cont)\n",
    "        \n",
    "        # Concatenate both outputs and pass through final head\n",
    "        combined = torch.cat([img_out, tab_out], dim=1)\n",
    "        return self.head(combined)\n",
    "\n",
    "# Model 2: Uses EfficientFormerV2 instead of ResNet50 for the image component\n",
    "class ImageTabularModel_2(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, ps=0.5):\n",
    "        super().__init__()\n",
    "        self.cnn = timm.create_model(\"efficientformerv2_s2\", pretrained=True)\n",
    "        self.tab_net = TabularModel(emb_szs, n_cont, out_sz, layers, ps)\n",
    "        self.head = nn.Linear(1002, out_sz)  # adjust if needed\n",
    "\n",
    "    def forward(self, x_img, x_cat, x_cont):\n",
    "        if x_cat.dtype != torch.long:\n",
    "            x_cat = x_cat.long()\n",
    "        img_out = self.cnn(x_img)\n",
    "        tab_out = self.tab_net(x_cat, x_cont)\n",
    "        combined = torch.cat([img_out, tab_out], dim=1)\n",
    "        return self.head(combined)\n",
    "\n",
    "# --- Initialize Models and Learners ---\n",
    "\n",
    "# Initialize both hybrid models with selected layer sizes\n",
    "model_1 = ImageTabularModel_1(emb_szs, n_cont, out_sz, layers=[512, 256, 128], ps=0.5).to(device)\n",
    "model_2 = ImageTabularModel_2(emb_szs, n_cont, out_sz, layers=[512, 256, 128], ps=0.5).to(device)\n",
    "\n",
    "# Enable multi-GPU training if available\n",
    "model_1 = torch.nn.DataParallel(model_1)\n",
    "model_2 = torch.nn.DataParallel(model_2)\n",
    "\n",
    "# Define the loss function for classification\n",
    "loss_func = CrossEntropyLossFlat()\n",
    "\n",
    "# Build FastAI Learner for training and validation with model_1\n",
    "learn_1 = Learner(\n",
    "    dls, model_1, loss_func=loss_func,\n",
    "    opt_func=partial(Adam, lr=0.001),\n",
    "    metrics=accuracy,\n",
    "    cbs=SaveModelCallback(monitor='valid_loss'),\n",
    "    wd=1e-3\n",
    ")\n",
    "\n",
    "# Same learner setup for model_2\n",
    "learn_2 = Learner(\n",
    "    dls, model_2, loss_func=loss_func,\n",
    "    opt_func=partial(Adam, lr=0.001),\n",
    "    metrics=accuracy,\n",
    "    cbs=SaveModelCallback(monitor='valid_loss'),\n",
    "    wd=1e-3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c3707",
   "metadata": {},
   "source": [
    "This section implements a hybrid deep learning model combining image features (via CNNs like ResNet50 or EfficientFormerV2) with structured tabular features (via FastAI's TabularModel). It supports multi-modal learning using PyTorch and FastAI, with model selection and training optimised using learners and callbacks. Useful in medical imaging, finance, or e-commerce where both image and metadata are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be634b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make cuDNN pick the fastest convolution algorithms for your fixed image size\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "002961eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train in float16 where safe (cuts compute + memory, usually 1.3–2× faster)\n",
    "learn_1 = learn_1.to_fp16()\n",
    "learn_2 = learn_2.to_fp16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e2e45d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze ResNet50 backbone in learn_1 (it’s mostly frozen already, but this is robust)\n",
    "m1 = learn_1.model.module if hasattr(learn_1.model, \"module\") else learn_1.model\n",
    "if hasattr(m1, \"cnn\"):\n",
    "    for p in m1.cnn.parameters(): p.requires_grad = False\n",
    "    # keep the final fc + head trainable\n",
    "    if hasattr(m1.cnn, \"fc\"):\n",
    "        for p in m1.cnn.fc.parameters(): p.requires_grad = True\n",
    "\n",
    "# freeze EfficientFormerV2 backbone in learn_2 (this one usually trains all layers by default)\n",
    "m2 = learn_2.model.module if hasattr(learn_2.model, \"module\") else learn_2.model\n",
    "if hasattr(m2, \"cnn\"):\n",
    "    for p in m2.cnn.parameters(): p.requires_grad = False    # huge speedup\n",
    "    # keep your tabular + head layers trainable\n",
    "    if hasattr(m2, \"head\"):\n",
    "        for p in m2.head.parameters(): p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30423ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in m2.cnn.parameters(): p.requires_grad = True  # then run a short fine_tune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf60c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# larger batches = fewer steps; adjust if GPU RAM is tight\n",
    "_fast_bs = 256  # try 256; if OOM, drop to 192/128\n",
    "\n",
    "# on Windows with HDF5, 0 or 2 workers are usually best; pin_memory speeds host->GPU copies\n",
    "train_loader = DataLoader(train_dataset, batch_size=_fast_bs, shuffle=True,\n",
    "                          num_workers=2, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
    "\n",
    "# validation can be even bigger since it doesn't backprop\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=_fast_bs*2, shuffle=False,\n",
    "                          num_workers=2, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
    "\n",
    "# rebuild the fastai DataLoaders with the tuned PyTorch loaders\n",
    "dls = DataLoaders(train_loader, valid_loader)\n",
    "learn_1.dls = dls\n",
    "learn_2.dls = dls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bac910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yashwanth\\anaconda3\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
      "C:\\Users\\Yashwanth\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yashwanth\\anaconda3\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
      "C:\\Users\\Yashwanth\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\amp\\grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1175 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yashwanth\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Define a slightly smaller LR (safer when using bigger batch & fp16)\n",
    "custom_lr = 0.003\n",
    "\n",
    "# QUICK PASS: short, fast runs to get results sooner\n",
    "learn_1.fit_one_cycle(1, lr_max=custom_lr)      # keep\n",
    "learn_1.fine_tune(2, base_lr=custom_lr/2)       # was 5 → try 2 for speed\n",
    "\n",
    "learn_2.fit_one_cycle(1, lr_max=custom_lr)      # was 3 → try 1 first\n",
    "learn_2.fine_tune(2, base_lr=custom_lr/2)       # was 5 → try 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c7130c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='2350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2350 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Define the lr\n",
    "custom_lr=0.005\n",
    "\n",
    "#Train and fine-tune the model\n",
    "learn_1.fit_one_cycle(1, lr_max=custom_lr)\n",
    "learn_1.fine_tune(5)\n",
    "\n",
    "learn_2.fit_one_cycle(3, lr_max=custom_lr)\n",
    "learn_2.fine_tune(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3150369b",
   "metadata": {},
   "source": [
    "# Test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823e9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, cat_names):\n",
    "    \n",
    "    \n",
    "    # Drop columns \n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "    \n",
    "    # Add number of pictures for each patient\n",
    "    df['numb_pic'] = df.groupby('patient_id')['patient_id'].transform('count')\n",
    "    \n",
    "    # Fill missing values with the mode\n",
    "    if 'age_approx' in df.columns:\n",
    "        mode_age = df['age_approx'].mode()[0]\n",
    "        df['age_approx'] = df['age_approx'].fillna(mode_age)\n",
    "    \n",
    "    if 'sex' in df.columns:\n",
    "        mode_sex = df['sex'].mode()[0]\n",
    "        df['sex'] = df['sex'].fillna(mode_sex)\n",
    "    \n",
    "    # Convert categorical columns to dummies\n",
    "    df = pd.get_dummies(df, columns=cat_names, prefix=cat_names)\n",
    "    \n",
    "    # Get new categorical column names\n",
    "    new_cat_columns = [col for col in df.columns if any(col.startswith(name + '_') for name in cat_names)]\n",
    "    \n",
    "    # Ensure 'isic_id' in df has the correct file extension\n",
    "    # if 'isic_id' in df.columns:\n",
    "    #     df['isic_id'] = df['isic_id'].apply(lambda x: x.strip() + '.jpg')\n",
    "    \n",
    "    return df, new_cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900c5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
