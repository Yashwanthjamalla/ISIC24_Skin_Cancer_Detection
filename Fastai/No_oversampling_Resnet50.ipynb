{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1250c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastcore.parallel import *\n",
    "import fastai\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    " \n",
    "\n",
    "# Set paths\n",
    "path = Path(\"/home/webadmin/Desktop/isic/\")\n",
    "train_metadata_path = path / 'train-metadata.csv'\n",
    "images_path = path / '/home/webadmin/Desktop/isic/image'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67134930",
   "metadata": {},
   "source": [
    "# Preparing metadata file and merge with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b52b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata append\n",
    "\n",
    "df = pd.read_csv(train_metadata_path,low_memory=False)\n",
    "\n",
    "# Drop specified columns\n",
    "columns_to_drop = ['copyright_license', 'attribution', 'image_type', 'iddx_1', 'iddx_2', 'iddx_3', 'iddx_4',\n",
    "                       'iddx_5', 'iddx_full', 'mel_mitotic_index', 'mel_thick_mm', 'tbp_tile_type', \n",
    "                       'tbp_lv_dnn_lesion_confidence', 'lesion_id']\n",
    "\n",
    "# Define categorical and continuous columns\n",
    "cat_names = [ 'sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple']\n",
    "cont_names = [x for x in df.columns if x not in cat_names + ['target', 'isic_id','patient_id']+columns_to_drop]\n",
    "y_col = 'target'\n",
    "image_col = 'isic_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fbff428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, cat_names):\n",
    "    \n",
    "    \n",
    "    # Drop columns \n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "    \n",
    "    # Add number of pictures for each patient\n",
    "    df['numb_pic'] = df.groupby('patient_id')['patient_id'].transform('count')\n",
    "    \n",
    "    # Fill missing values with the mode\n",
    "    if 'age_approx' in df.columns:\n",
    "        mode_age = df['age_approx'].mode()[0]\n",
    "        df['age_approx'] = df['age_approx'].fillna(mode_age)\n",
    "    \n",
    "    if 'sex' in df.columns:\n",
    "        mode_sex = df['sex'].mode()[0]\n",
    "        df['sex'] = df['sex'].fillna(mode_sex)\n",
    "    \n",
    "    # Convert categorical columns to dummies\n",
    "    df = pd.get_dummies(df, columns=cat_names, prefix=cat_names)\n",
    "    \n",
    "    # Get new categorical column names\n",
    "    new_cat_columns = [col for col in df.columns if any(col.startswith(name + '_') for name in cat_names)]\n",
    "    \n",
    "    # Ensure 'isic_id' in df has the correct file extension\n",
    "    if 'isic_id' in df.columns:\n",
    "         df['isic_id'] = df['isic_id'].apply(lambda x: x.strip() + '.jpg')\n",
    "    \n",
    "    return df, new_cat_columns\n",
    "\n",
    "#Apply to df\n",
    "df, new_cat_columns= process_data(df,cat_names)  \n",
    "\n",
    "# Load images and create DataFrame\n",
    "images = get_image_files(images_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b633b9",
   "metadata": {},
   "source": [
    "# Create a custom dataset that includes both image and tabular data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97bfb542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "class ImageTabDataset(Dataset):\n",
    "    def __init__(self, df, image_files, new_cat_columns, cont_names, y_col, img_size=(137, 137), transform=None):\n",
    "        self.df = df\n",
    "        self.image_files = [Path(img) for img in image_files]\n",
    "        self.new_cat_columns = new_cat_columns\n",
    "        self.cont_names = cont_names\n",
    "        self.y_col = y_col\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize(self.img_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        # keep both with-extension and stem keys, lowercased for robust matching\n",
    "        self.image_dict = {}\n",
    "        for img in self.image_files:\n",
    "            self.image_dict[img.name.lower()] = img\n",
    "            self.image_dict[img.stem.lower()] = img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Verify that self.df is a DataFrame\n",
    "        if not isinstance(self.df, pd.DataFrame):\n",
    "            raise TypeError(f\"Expected self.df to be a DataFrame, but got {type(self.df).__name__}\")\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # --- robust ID lookup ---\n",
    "        isic_id_raw = row['isic_id']\n",
    "        key = str(isic_id_raw).strip().lower()\n",
    "\n",
    "        # try direct\n",
    "        if key not in self.image_dict:\n",
    "            # add common extensions if missing\n",
    "            if not (key.endswith('.jpg') or key.endswith('.jpeg') or key.endswith('.png')):\n",
    "                if key + '.jpg' in self.image_dict:\n",
    "                    key = key + '.jpg'\n",
    "                elif key + '.jpeg' in self.image_dict:\n",
    "                    key = key + '.jpeg'\n",
    "                elif key + '.png' in self.image_dict:\n",
    "                    key = key + '.png'\n",
    "\n",
    "        if key not in self.image_dict:\n",
    "            raise KeyError(f\"Image ID {isic_id_raw} not found in image_dict.\")\n",
    "\n",
    "        img_path = self.image_dict[key]\n",
    "        # ------------------------\n",
    "\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        new_cat_columns = torch.tensor(row[self.new_cat_columns].values.astype(float)).float()\n",
    "        cont = torch.tensor(row[self.cont_names].values.astype(float)).float()\n",
    "        y = torch.tensor(row[self.y_col]).long()\n",
    "\n",
    "        return img, new_cat_columns, cont, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa79827",
   "metadata": {},
   "source": [
    "# Combine image and tabular data into a DataBlock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8996f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from fastai.tabular.all import TabularPandas, get_emb_sz, TabularModel, Learner, CrossEntropyLossFlat, accuracy\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    " \n",
    "\n",
    "# Stratified split\n",
    "def stratified_splitter(df, valid_pct=0.25, seed=42):\n",
    "    train_indices, valid_indices = train_test_split(\n",
    "        df.index,\n",
    "        test_size=valid_pct,\n",
    "        stratify=df[y_col],  # stratify by target column\n",
    "        random_state=seed\n",
    "    )\n",
    "    return train_indices, valid_indices\n",
    "\n",
    "# Perform the split\n",
    "train_indices, valid_indices = stratified_splitter(df)\n",
    "\n",
    "# Create train and validation dataframes\n",
    "train_df = df.iloc[train_indices]\n",
    "valid_df = df.iloc[valid_indices]\n",
    "\n",
    "# Define the datasets\n",
    "train_dataset = ImageTabDataset(train_df,images, new_cat_columns, cont_names, y_col)\n",
    "valid_dataset = ImageTabDataset(valid_df,images, new_cat_columns, cont_names, y_col)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# Create a DataLoaders object\n",
    "dls = DataLoaders(train_loader, valid_loader)\n",
    "\n",
    "# Manually get embedding sizes\n",
    "def get_emb_szs(df, new_cat_columns):\n",
    "    return [(df[col].nunique() + 1, min(50, (df[col].nunique() + 1) // 2)) for col in new_cat_columns]\n",
    "\n",
    "# Calculate embedding sizes\n",
    "emb_szs = get_emb_szs(train_df, new_cat_columns)\n",
    "n_cont = len(cont_names)\n",
    "out_sz = len(train_df[y_col].unique())\n",
    "\n",
    "# Define custom model\n",
    "class ImageTabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, ps=0.5):\n",
    "        super().__init__()\n",
    "        # Initialize ResNet50 without pre-trained weights\n",
    "        self.cnn = models.resnet50(weights=None)  # Use weights=None\n",
    "        \n",
    "        # Load custom weights\n",
    "        self.cnn.load_state_dict(torch.load('/home/webadmin/Desktop/ISIC24_Skin_Cancer_Detection/Fastai/resnet50-11ad3fa6.pth'))\n",
    "        \n",
    "        # Adjust the final layer if needed\n",
    "        num_ftrs = self.cnn.fc.in_features\n",
    "        self.cnn.fc = nn.Linear(num_ftrs, out_sz)  # Set the number of output features\n",
    "        \n",
    "        # Initialize the tabular model\n",
    "        self.tab_net = TabularModel(emb_szs, n_cont, out_sz, layers, ps)\n",
    "        \n",
    "        # Define the head that combines image and tabular outputs\n",
    "        self.head = nn.Linear(out_sz * 2, out_sz)  # Adjust as needed\n",
    "\n",
    "    def forward(self, x_img, x_cat, x_cont):\n",
    "        if x_cat.dtype != torch.long:\n",
    "            x_cat = x_cat.long()\n",
    "        \n",
    "        img_out = self.cnn(x_img)\n",
    "        tab_out = self.tab_net(x_cat, x_cont)\n",
    "        combined = torch.cat([img_out, tab_out], dim=1)\n",
    "        return self.head(combined)\n",
    "\n",
    "# Create the model\n",
    "model = ImageTabularModel(emb_szs, n_cont, out_sz, layers=[512, 256, 128], ps=0.5).to(device)\n",
    "\n",
    "# Make the model parallel\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "# Create Learner\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6959e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your model file\n",
    "model_path_out = Path('/kaggle/working/models/resnet50_full')\n",
    "model_path_in = Path('/kaggle/input/resnet50/pytorch/resnet-3-epochs/1/resnet50_full.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cf0ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the learning rate\n",
    "#learn.lr_find(suggest_funcs=(slide, valley))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f1b930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='2350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2350 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if the model file exists\n",
    "#Define the number of epochs\n",
    "numb_epochs=3\n",
    "\n",
    "# Define custom learning rate\n",
    "custom_lr =0.3\n",
    "learn.fine_tune(1)\n",
    "'''\n",
    "if not model_path_in.exists():\n",
    "    # Model does not exist, so train and save the model\n",
    "    learn.fit_one_cycle(3, lr_max=custom_lr)\n",
    "    learn.save(model_path_out.stem)\n",
    "else:\n",
    "    # Model exists, so load, fine-tune, and save it\n",
    "    learn.load(model_path_in.stem)\n",
    "    learn.fine_tune(1)\n",
    "    learn.save(model_path_out.stem)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4286ce4b",
   "metadata": {},
   "source": [
    "# Test part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/home/webadmin/Desktop/isic/image\"\n",
    "TEST_HDF = f'{ROOT_DIR}/test-image.hdf5'\n",
    "TEST_CSV = f'{ROOT_DIR}/test-metadata.csv'\n",
    "\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "\n",
    "#Apply to df\n",
    "df_test, _= process_data(df_test,cat_names)  \n",
    "\n",
    "# Ensure the test set has the same dummy variable columns as the training set\n",
    "for col in new_cat_columns:\n",
    "    if col not in df_test:\n",
    "        df_test[col] = 0\n",
    "\n",
    "# Create a list of columns from the training set excluding 'target'\n",
    "train_columns = [col for col in df.columns if col != 'target']\n",
    "\n",
    "# Reorder the test set columns to match the training set columns (excluding 'target')\n",
    "df_test = df_test[train_columns]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e4802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import h5py\n",
    "from io import BytesIO\n",
    "import torch\n",
    "\n",
    "class CombinedDataset_test(Dataset):\n",
    "    def __init__(self, df, file_hdf, cat_names, train_columns, transforms=None, target_size=(137, 137)):\n",
    "        self.df = df\n",
    "        self.fp_hdf = h5py.File(file_hdf, mode=\"r\")\n",
    "        self.isic_ids = df['isic_id'].values\n",
    "        self.transforms = transforms\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        self.cat_names = cat_names\n",
    "        self.cont_names = cont_names\n",
    "        \n",
    "        # Convert categorical columns to numerical codes\n",
    "        for cat in cat_names:\n",
    "            if cat in self.df.columns:\n",
    "                self.df[cat] = self.df[cat].astype('category').cat.codes\n",
    "        \n",
    "        # Convert all other columns to numeric\n",
    "        for col in df.columns:\n",
    "            if col not in cat_names  + ['isic_id']:\n",
    "                self.df[col] = pd.to_numeric(self.df[col], errors='coerce')\n",
    "        \n",
    "      \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get image\n",
    "        isic_id = self.isic_ids[index]\n",
    "        img = Image.open(BytesIO(self.fp_hdf[isic_id][()])).convert('RGB')\n",
    "        img = img.resize(self.target_size, Image.LANCZOS)\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        # Get tabular data\n",
    "        tabular_data = self.df.iloc[index]\n",
    "        \n",
    "        # Separate categorical and continuous data\n",
    "        cat_data = tabular_data[self.cat_names] \n",
    "        cont_data = tabular_data[self.cont_names] \n",
    "        \n",
    "        # Convert to tensors\n",
    "        cat_tensor = torch.tensor(cat_data.values.astype(int), dtype=torch.long)\n",
    "        cont_tensor = torch.tensor(cont_data.values.astype(float), dtype=torch.float32)\n",
    "        y=torch.tensor(0.7, dtype=torch.long) # Dummy variable to avoid errors\n",
    "        return img, cat_tensor, cont_tensor,y\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a9d37",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define the transformations\n",
    "data_transforms = T.Compose([\n",
    "    T.Resize((137, 137)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'valid_batch_size': 64,  # Batch size for validation\n",
    "}\n",
    "\n",
    "# Create the combined dataset\n",
    "combined_dataset = CombinedDataset_test(df_test, TEST_HDF, new_cat_columns, cont_names, transforms=data_transforms)\n",
    "\n",
    "# Define DataLoader\n",
    "test_loader = DataLoader(combined_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                         num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "learn.model.eval()\n",
    "\n",
    "# Run predictions on the test DataLoader\n",
    "preds, targs = learn.get_preds(dl=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7243576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Initialize lists to collect predictions and ids\n",
    "all_probs_class_1 = []\n",
    "all_isic_ids = []\n",
    "\n",
    "# Example function to handle probabilities\n",
    "def process_probabilities(probabilities):\n",
    "    # Replace NaN values with 0\n",
    "    probabilities = np.nan_to_num(probabilities, nan=0.0)\n",
    "    \n",
    "    # Ensure probabilities are within the range [0, 1]\n",
    "    probabilities = np.clip(probabilities, 0, 1)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "# Get predictions from the DataLoader\n",
    "with torch.no_grad():\n",
    "    # Obtain predictions for the entire test set\n",
    "    logits, _ = learn.get_preds(dl=test_loader)  # The second output is targets, which is ignored\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "    # Extract the probabilities for class ID 1\n",
    "    prob_class_1 = probabilities[:, 1].detach().cpu().numpy()\n",
    "    \n",
    "    #process probabilities to ensure they are between 0 and 1\n",
    "    prob_class_1 = process_probabilities(prob_class_1)\n",
    "    \n",
    "    # Collect the probabilities and ids\n",
    "    all_probs_class_1.extend(prob_class_1)\n",
    "    all_isic_ids.extend(combined_dataset.isic_ids[:len(prob_class_1)])  # Use the dataset directly\n",
    "\n",
    "# Convert lists to arrays or DataFrame if needed\n",
    "import pandas as pd\n",
    "results = pd.DataFrame({\n",
    "    'isic_id': all_isic_ids,\n",
    "    'target': all_probs_class_1\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9196fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ad5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38_PT_and_TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
