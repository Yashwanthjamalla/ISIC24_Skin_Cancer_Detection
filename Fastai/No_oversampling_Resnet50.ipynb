{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1250c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastcore.parallel import *\n",
    "import fastai\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    " \n",
    "\n",
    "# Set paths\n",
    "path = Path(\"/home/webadmin/Desktop/isic/\")\n",
    "train_metadata_path = path / 'train-metadata.csv'\n",
    "images_path = path / '/home/webadmin/Desktop/isic/image'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67134930",
   "metadata": {},
   "source": [
    "# Preparing metadata file and merge with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b52b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata append\n",
    "\n",
    "df = pd.read_csv(train_metadata_path,low_memory=False)\n",
    "\n",
    "# Drop specified columns\n",
    "columns_to_drop = ['copyright_license', 'attribution', 'image_type', 'iddx_1', 'iddx_2', 'iddx_3', 'iddx_4',\n",
    "                       'iddx_5', 'iddx_full', 'mel_mitotic_index', 'mel_thick_mm', 'tbp_tile_type', \n",
    "                       'tbp_lv_dnn_lesion_confidence', 'lesion_id']\n",
    "\n",
    "# Define categorical and continuous columns\n",
    "cat_names = [ 'sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple']\n",
    "cont_names = [x for x in df.columns if x not in cat_names + ['target', 'isic_id','patient_id']+columns_to_drop]\n",
    "y_col = 'target'\n",
    "image_col = 'isic_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fbff428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, cat_names):\n",
    "    \n",
    "    \n",
    "    # Drop columns \n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "    \n",
    "    # Add number of pictures for each patient\n",
    "    df['numb_pic'] = df.groupby('patient_id')['patient_id'].transform('count')\n",
    "    \n",
    "    # Fill missing values with the mode\n",
    "    if 'age_approx' in df.columns:\n",
    "        mode_age = df['age_approx'].mode()[0]\n",
    "        df['age_approx'] = df['age_approx'].fillna(mode_age)\n",
    "    \n",
    "    if 'sex' in df.columns:\n",
    "        mode_sex = df['sex'].mode()[0]\n",
    "        df['sex'] = df['sex'].fillna(mode_sex)\n",
    "    \n",
    "    # Convert categorical columns to dummies\n",
    "    df = pd.get_dummies(df, columns=cat_names, prefix=cat_names)\n",
    "    \n",
    "    # Get new categorical column names\n",
    "    new_cat_columns = [col for col in df.columns if any(col.startswith(name + '_') for name in cat_names)]\n",
    "    \n",
    "    # Ensure 'isic_id' in df has the correct file extension\n",
    "    if 'isic_id' in df.columns:\n",
    "         df['isic_id'] = df['isic_id'].apply(lambda x: x.strip() + '.jpg')\n",
    "    \n",
    "    return df, new_cat_columns\n",
    "\n",
    "#Apply to df\n",
    "df, new_cat_columns= process_data(df,cat_names)  \n",
    "\n",
    "# Load images and create DataFrame\n",
    "images = get_image_files(images_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b633b9",
   "metadata": {},
   "source": [
    "# Create a custom dataset that includes both image and tabular data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97bfb542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "class ImageTabDataset(Dataset):\n",
    "    def __init__(self, df, image_files, new_cat_columns, cont_names, y_col, img_size=(137, 137), transform=None):\n",
    "        self.df = df\n",
    "        self.image_files = [Path(img) for img in image_files]\n",
    "        self.new_cat_columns = new_cat_columns\n",
    "        self.cont_names = cont_names\n",
    "        self.y_col = y_col\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize(self.img_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        # keep both with-extension and stem keys, lowercased for robust matching\n",
    "        self.image_dict = {}\n",
    "        for img in self.image_files:\n",
    "            self.image_dict[img.name.lower()] = img\n",
    "            self.image_dict[img.stem.lower()] = img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Verify that self.df is a DataFrame\n",
    "        if not isinstance(self.df, pd.DataFrame):\n",
    "            raise TypeError(f\"Expected self.df to be a DataFrame, but got {type(self.df).__name__}\")\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # --- robust ID lookup ---\n",
    "        isic_id_raw = row['isic_id']\n",
    "        key = str(isic_id_raw).strip().lower()\n",
    "\n",
    "        # try direct\n",
    "        if key not in self.image_dict:\n",
    "            # add common extensions if missing\n",
    "            if not (key.endswith('.jpg') or key.endswith('.jpeg') or key.endswith('.png')):\n",
    "                if key + '.jpg' in self.image_dict:\n",
    "                    key = key + '.jpg'\n",
    "                elif key + '.jpeg' in self.image_dict:\n",
    "                    key = key + '.jpeg'\n",
    "                elif key + '.png' in self.image_dict:\n",
    "                    key = key + '.png'\n",
    "\n",
    "        if key not in self.image_dict:\n",
    "            raise KeyError(f\"Image ID {isic_id_raw} not found in image_dict.\")\n",
    "\n",
    "        img_path = self.image_dict[key]\n",
    "        # ------------------------\n",
    "\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        new_cat_columns = torch.tensor(row[self.new_cat_columns].values.astype(float)).float()\n",
    "        cont = torch.tensor(row[self.cont_names].values.astype(float)).float()\n",
    "        y = torch.tensor(row[self.y_col]).long()\n",
    "\n",
    "        return img, new_cat_columns, cont, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa79827",
   "metadata": {},
   "source": [
    "# Combine image and tabular data into a DataBlock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8996f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from fastai.tabular.all import TabularPandas, get_emb_sz, TabularModel, Learner, CrossEntropyLossFlat, accuracy\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    " \n",
    "\n",
    "# Stratified split\n",
    "def stratified_splitter(df, valid_pct=0.25, seed=42):\n",
    "    train_indices, valid_indices = train_test_split(\n",
    "        df.index,\n",
    "        test_size=valid_pct,\n",
    "        stratify=df[y_col],  # stratify by target column\n",
    "        random_state=seed\n",
    "    )\n",
    "    return train_indices, valid_indices\n",
    "\n",
    "# Perform the split\n",
    "train_indices, valid_indices = stratified_splitter(df)\n",
    "\n",
    "# Create train and validation dataframes\n",
    "train_df = df.iloc[train_indices]\n",
    "valid_df = df.iloc[valid_indices]\n",
    "\n",
    "# Define the datasets\n",
    "train_dataset = ImageTabDataset(train_df,images, new_cat_columns, cont_names, y_col)\n",
    "valid_dataset = ImageTabDataset(valid_df,images, new_cat_columns, cont_names, y_col)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# Create a DataLoaders object\n",
    "dls = DataLoaders(train_loader, valid_loader)\n",
    "\n",
    "# Manually get embedding sizes\n",
    "def get_emb_szs(df, new_cat_columns):\n",
    "    return [(df[col].nunique() + 1, min(50, (df[col].nunique() + 1) // 2)) for col in new_cat_columns]\n",
    "\n",
    "# Calculate embedding sizes\n",
    "emb_szs = get_emb_szs(train_df, new_cat_columns)\n",
    "n_cont = len(cont_names)\n",
    "out_sz = len(train_df[y_col].unique())\n",
    "\n",
    "# Define custom model\n",
    "class ImageTabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, ps=0.5):\n",
    "        super().__init__()\n",
    "        # Initialize ResNet50 without pre-trained weights\n",
    "        self.cnn = models.resnet50(weights=None)  # Use weights=None\n",
    "        \n",
    "        # Load custom weights\n",
    "        self.cnn.load_state_dict(torch.load('/home/webadmin/Desktop/ISIC24_Skin_Cancer_Detection/Fastai/resnet50-11ad3fa6.pth'))\n",
    "        \n",
    "        # Adjust the final layer if needed\n",
    "        num_ftrs = self.cnn.fc.in_features\n",
    "        self.cnn.fc = nn.Linear(num_ftrs, out_sz)  # Set the number of output features\n",
    "        \n",
    "        # Initialize the tabular model\n",
    "        self.tab_net = TabularModel(emb_szs, n_cont, out_sz, layers, ps)\n",
    "        \n",
    "        # Define the head that combines image and tabular outputs\n",
    "        self.head = nn.Linear(out_sz * 2, out_sz)  # Adjust as needed\n",
    "\n",
    "    def forward(self, x_img, x_cat, x_cont):\n",
    "        if x_cat.dtype != torch.long:\n",
    "            x_cat = x_cat.long()\n",
    "        \n",
    "        img_out = self.cnn(x_img)\n",
    "        tab_out = self.tab_net(x_cat, x_cont)\n",
    "        combined = torch.cat([img_out, tab_out], dim=1)\n",
    "        return self.head(combined)\n",
    "\n",
    "# Create the model\n",
    "model = ImageTabularModel(emb_szs, n_cont, out_sz, layers=[512, 256, 128], ps=0.5).to(device)\n",
    "\n",
    "# Make the model parallel\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "# Create Learner\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6959e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your model file\n",
    "model_path_out = Path('/kaggle/working/models/resnet50_full')\n",
    "model_path_in = Path('/kaggle/input/resnet50/pytorch/resnet-3-epochs/1/resnet50_full.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cf0ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the learning rate\n",
    "#learn.lr_find(suggest_funcs=(slide, valley))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6f1b930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>25:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>0.999033</td>\n",
       "      <td>25:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nif not model_path_in.exists():\\n    # Model does not exist, so train and save the model\\n    learn.fit_one_cycle(3, lr_max=custom_lr)\\n    learn.save(model_path_out.stem)\\nelse:\\n    # Model exists, so load, fine-tune, and save it\\n    learn.load(model_path_in.stem)\\n    learn.fine_tune(1)\\n    learn.save(model_path_out.stem)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model file exists\n",
    "#Define the number of epochs\n",
    "numb_epochs=3\n",
    "\n",
    "# Define custom learning rate\n",
    "custom_lr =0.3\n",
    "learn.fine_tune(1)\n",
    "'''\n",
    "if not model_path_in.exists():\n",
    "    # Model does not exist, so train and save the model\n",
    "    learn.fit_one_cycle(3, lr_max=custom_lr)\n",
    "    learn.save(model_path_out.stem)\n",
    "else:\n",
    "    # Model exists, so load, fine-tune, and save it\n",
    "    learn.load(model_path_in.stem)\n",
    "    learn.fine_tune(1)\n",
    "    learn.save(model_path_out.stem)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4286ce4b",
   "metadata": {},
   "source": [
    "# Test part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eff6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/home/webadmin/Desktop/isic/\"\n",
    "TEST_HDF = f'{ROOT_DIR}/test-image.hdf5'\n",
    "TEST_CSV = f'{ROOT_DIR}/test-metadata.csv'\n",
    "\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "\n",
    "#Apply to df\n",
    "df_test, _= process_data(df_test,cat_names)  \n",
    "\n",
    "# Ensure the test set has the same dummy variable columns as the training set\n",
    "for col in new_cat_columns:\n",
    "    if col not in df_test:\n",
    "        df_test[col] = 0\n",
    "\n",
    "# Create a list of columns from the training set excluding 'target'\n",
    "train_columns = [col for col in df.columns if col != 'target']\n",
    "\n",
    "# Reorder the test set columns to match the training set columns (excluding 'target')\n",
    "df_test = df_test[train_columns]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f38e4802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def _fetch_h5_image(fp, isic_id):\n",
    "    \"\"\"\n",
    "    Try several key variants and groups:\n",
    "      - 'ISIC_xxxxxx' (no extension), then 'ISIC_xxxxxx.jpg/.jpeg/.png'\n",
    "      - groups: 'oversampled_images', 'images', 'image', 'train_images', 'train', 'test', root\n",
    "    Returns a PIL.Image in RGB.\n",
    "    \"\"\"\n",
    "    raw = str(isic_id).strip()\n",
    "    stem = raw.rsplit('.', 1)[0]  # drop extension if present\n",
    "    name_candidates = [stem, stem + '.jpg', stem + '.jpeg', stem + '.png']\n",
    "    group_candidates = ['oversampled_images', 'images', 'image', 'train_images', 'train', 'test', None]\n",
    "\n",
    "    for grp in group_candidates:\n",
    "        if grp is not None and grp not in fp:\n",
    "            continue\n",
    "        node = fp[grp] if grp is not None else fp\n",
    "        for name in name_candidates:\n",
    "            if name in node:\n",
    "                ds = node[name]\n",
    "                try:\n",
    "                    arr = ds[()]  # dataset -> numpy or bytes\n",
    "                except Exception:\n",
    "                    # if it’s a group with one child dataset\n",
    "                    kids = list(ds.keys())\n",
    "                    if not kids: \n",
    "                        continue\n",
    "                    arr = ds[kids[0]][()]\n",
    "\n",
    "                if isinstance(arr, (bytes, bytearray)):         # raw encoded image bytes\n",
    "                    return Image.open(BytesIO(arr)).convert('RGB')\n",
    "                else:                                           # numpy array (H,W,3) or (3,H,W)\n",
    "                    if arr.ndim == 3 and arr.shape[0] in (1,3) and arr.shape[0] != arr.shape[-1]:\n",
    "                        arr = np.moveaxis(arr, 0, -1)          # CHW -> HWC\n",
    "                    return Image.fromarray(arr).convert('RGB')\n",
    "    # Nothing matched -> good error message\n",
    "    tops = list(fp.keys())\n",
    "    raise KeyError(f\"{raw} not found in HDF5. Top-level keys: {tops[:8]}{'...' if len(tops)>8 else ''}\")\n",
    "\n",
    "\n",
    "class CombinedDataset_test(Dataset):\n",
    "    # keep your call-site the same: CombinedDataset_test(df_test, TEST_HDF, new_cat_columns, cont_names, ...)\n",
    "    def __init__(self, df, file_hdf, cat_names, cont_names, transforms=None, target_size=(137, 137)):\n",
    "        self.df = df\n",
    "        self.fp_hdf = h5py.File(file_hdf, mode=\"r\")\n",
    "        self.isic_ids = df['isic_id'].values\n",
    "        self.transforms = transforms\n",
    "        self.target_size = target_size\n",
    "\n",
    "        self.cat_names = cat_names\n",
    "        self.cont_names = cont_names\n",
    "\n",
    "        # Convert categorical columns to codes if present\n",
    "        for cat in cat_names:\n",
    "            if cat in self.df.columns:\n",
    "                self.df[cat] = self.df[cat].astype('category').cat.codes\n",
    "\n",
    "        # Convert all other columns to numeric (except isic_id)\n",
    "        for col in df.columns:\n",
    "            if col not in cat_names + ['isic_id']:\n",
    "                self.df[col] = pd.to_numeric(self.df[col], errors='coerce')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        isic_id = self.isic_ids[index]\n",
    "\n",
    "        # --- robust HDF5 lookup (handles missing .jpg and groups) ---\n",
    "        img = _fetch_h5_image(self.fp_hdf, isic_id)\n",
    "        img = img.resize(self.target_size, Image.LANCZOS)\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        # tabular split\n",
    "        row = self.df.iloc[index]\n",
    "        cat_data  = row[self.cat_names]      # already integer-coded above\n",
    "        cont_data = row[self.cont_names]\n",
    "\n",
    "        cat_tensor  = torch.tensor(cat_data.values.astype(int),    dtype=torch.long)\n",
    "        cont_tensor = torch.tensor(cont_data.values.astype(float), dtype=torch.float32)\n",
    "        y = torch.tensor(0, dtype=torch.long)  # dummy target for API compatibility\n",
    "\n",
    "        return img, cat_tensor, cont_tensor, y\n",
    "\n",
    "    def __del__(self):\n",
    "        try:\n",
    "            self.fp_hdf.close()\n",
    "        except Exception:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e6a9d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Define the transformations\n",
    "data_transforms = T.Compose([\n",
    "    T.Resize((137, 137)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'valid_batch_size': 64,  # Batch size for validation\n",
    "}\n",
    "\n",
    "# Create the combined dataset\n",
    "combined_dataset = CombinedDataset_test(df_test, TEST_HDF, new_cat_columns, cont_names, transforms=data_transforms)\n",
    "\n",
    "# Define DataLoader\n",
    "test_loader = DataLoader(combined_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                         num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "learn.model.eval()\n",
    "\n",
    "# Run predictions on the test DataLoader\n",
    "preds, targs = learn.get_preds(dl=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7243576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Initialize lists to collect predictions and ids\n",
    "all_probs_class_1 = []\n",
    "all_isic_ids = []\n",
    "\n",
    "# Example function to handle probabilities\n",
    "def process_probabilities(probabilities):\n",
    "    # Replace NaN values with 0\n",
    "    probabilities = np.nan_to_num(probabilities, nan=0.0)\n",
    "    \n",
    "    # Ensure probabilities are within the range [0, 1]\n",
    "    probabilities = np.clip(probabilities, 0, 1)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "# Get predictions from the DataLoader\n",
    "with torch.no_grad():\n",
    "    # Obtain predictions for the entire test set\n",
    "    logits, _ = learn.get_preds(dl=test_loader)  # The second output is targets, which is ignored\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "    # Extract the probabilities for class ID 1\n",
    "    prob_class_1 = probabilities[:, 1].detach().cpu().numpy()\n",
    "    \n",
    "    #process probabilities to ensure they are between 0 and 1\n",
    "    prob_class_1 = process_probabilities(prob_class_1)\n",
    "    \n",
    "    # Collect the probabilities and ids\n",
    "    all_probs_class_1.extend(prob_class_1)\n",
    "    all_isic_ids.extend(combined_dataset.isic_ids[:len(prob_class_1)])  # Use the dataset directly\n",
    "\n",
    "# Convert lists to arrays or DataFrame if needed\n",
    "import pandas as pd\n",
    "results = pd.DataFrame({\n",
    "    'isic_id': all_isic_ids,\n",
    "    'target': all_probs_class_1\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d9196fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "133ad5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657.jpg</td>\n",
       "      <td>0.269085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729.jpg</td>\n",
       "      <td>0.269083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740.jpg</td>\n",
       "      <td>0.269101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            isic_id    target\n",
       "0  ISIC_0015657.jpg  0.269085\n",
       "1  ISIC_0015729.jpg  0.269083\n",
       "2  ISIC_0015740.jpg  0.269101"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38_PT_and_TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
