{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastai vision modules (datasets, transforms, models, etc.)\n",
    "from fastai.vision.all import *\n",
    "# parallel processing utils (fastai helper for faster preprocessing)\n",
    "from fastcore.parallel import *\n",
    "# main fastai package (needed if you use Learner, metrics, etc.)\n",
    "import fastai\n",
    "# data handling\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# PyTorch imports for custom datasets\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Set project paths\n",
    "# Root ISIC folder\n",
    "path = Path(\"/home/webadmin/Desktop/isic/\")\n",
    "# Training metadata (CSV with labels + info)\n",
    "train_metadata_path = path / 'train-metadata.csv'\n",
    "# Folder containing images (no need to put absolute path twice)\n",
    "images_path = path / 'image'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c14ef4",
   "metadata": {},
   "source": [
    "We used Fastai for building and training vision models.\n",
    "fastai.vision provides ready-to-use image transforms and model training pipelines.\n",
    "fastcore.parallel helps speed up preprocessing when applied to many images.\n",
    "PyTorch Dataset is imported to allow us to create a custom dataset class (for pairing metadata with images).\n",
    "Paths are managed using Pathlib, making code cleaner and more portable across systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67134930",
   "metadata": {},
   "source": [
    "# Preparing metadata file and merge with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b52b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata append\n",
    "\n",
    "df = pd.read_csv(train_metadata_path,low_memory=False)\n",
    "\n",
    "# Drop specified columns\n",
    "columns_to_drop = ['copyright_license', 'attribution', 'image_type', 'iddx_1', 'iddx_2', 'iddx_3', 'iddx_4',\n",
    "                       'iddx_5', 'iddx_full', 'mel_mitotic_index', 'mel_thick_mm', 'tbp_tile_type', \n",
    "                       'tbp_lv_dnn_lesion_confidence', 'lesion_id']\n",
    "\n",
    "# Define categorical and continuous columns\n",
    "cat_names = [ 'sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple']\n",
    "cont_names = [x for x in df.columns if x not in cat_names + ['target', 'isic_id','patient_id']+columns_to_drop]\n",
    "y_col = 'target'\n",
    "image_col = 'isic_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34de250f",
   "metadata": {},
   "source": [
    "Drop columns that are not useful for training.                  \n",
    "Split the features into two types:            \n",
    "   Categorical (like gender, body site). \n",
    "Continuous (numeric values).\n",
    "\n",
    "Set target as the label we want to predict and isic_id as the image reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fbff428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, cat_names):\n",
    "    \n",
    "    \n",
    "    # Drop columns \n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "    \n",
    "    # Add number of pictures for each patient\n",
    "    df['numb_pic'] = df.groupby('patient_id')['patient_id'].transform('count')\n",
    "    \n",
    "    # Fill missing values with the mode\n",
    "    if 'age_approx' in df.columns:\n",
    "        mode_age = df['age_approx'].mode()[0]\n",
    "        df['age_approx'] = df['age_approx'].fillna(mode_age)\n",
    "    \n",
    "    if 'sex' in df.columns:\n",
    "        mode_sex = df['sex'].mode()[0]\n",
    "        df['sex'] = df['sex'].fillna(mode_sex)\n",
    "    \n",
    "    # Convert categorical columns to dummies\n",
    "    df = pd.get_dummies(df, columns=cat_names, prefix=cat_names)\n",
    "    \n",
    "    # Get new categorical column names\n",
    "    new_cat_columns = [col for col in df.columns if any(col.startswith(name + '_') for name in cat_names)]\n",
    "    \n",
    "    # Ensure 'isic_id' in df has the correct file extension\n",
    "    if 'isic_id' in df.columns:\n",
    "         df['isic_id'] = df['isic_id'].apply(lambda x: x.strip() + '.jpg')\n",
    "    \n",
    "    return df, new_cat_columns\n",
    "\n",
    "#Apply to df\n",
    "df, new_cat_columns= process_data(df,cat_names)  \n",
    "\n",
    "# Load images and create DataFrame\n",
    "images = get_image_files(images_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d1e74",
   "metadata": {},
   "source": [
    "Here I am just cleaning up the metadata so it’s ready for training. First, I drop the columns that are not useful. Then I add a new column that counts how many images each patient has. For missing values like age and sex, I fill them with the most common value so there are no blanks. I also convert the categorical features into one-hot encoded columns so the model can understand them. Finally, I make sure the image IDs have the .jpg extension so they match with the actual image files. After this, the metadata is clean and properly aligned with the images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b633b9",
   "metadata": {},
   "source": [
    "# Create a custom dataset that includes both image and tabular data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bfb542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Custom dataset that returns image + tabular features + target\n",
    "class ImageTabDataset(Dataset):\n",
    "    def __init__(self, df, image_files, new_cat_columns, cont_names, y_col, img_size=(137, 137), transform=None):\n",
    "        self.df = df\n",
    "        # Convert image paths to Path objects\n",
    "        self.image_files = [Path(img) for img in image_files]\n",
    "        self.new_cat_columns = new_cat_columns\n",
    "        self.cont_names = cont_names\n",
    "        self.y_col = y_col\n",
    "        self.img_size = img_size\n",
    "        # Default transform: resize image and convert to tensor\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize(self.img_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        # Create a lookup dict for image files (by filename and stem, lowercase)\n",
    "        self.image_dict = {}\n",
    "        for img in self.image_files:\n",
    "            self.image_dict[img.name.lower()] = img\n",
    "            self.image_dict[img.stem.lower()] = img\n",
    "\n",
    "    def __len__(self):\n",
    "        # Length = number of rows in dataframe\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        # Make sure df is a DataFrame\n",
    "        if not isinstance(self.df, pd.DataFrame):\n",
    "            raise TypeError(f\"Expected self.df to be a DataFrame, but got {type(self.df).__name__}\")\n",
    "\n",
    "        # Get row at index\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # robust ID lookup for image\n",
    "        isic_id_raw = row['isic_id']\n",
    "        key = str(isic_id_raw).strip().lower()\n",
    "\n",
    "        # If ID not found, try adding common extensions\n",
    "        if key not in self.image_dict:\n",
    "            if not (key.endswith('.jpg') or key.endswith('.jpeg') or key.endswith('.png')):\n",
    "                if key + '.jpg' in self.image_dict:\n",
    "                    key = key + '.jpg'\n",
    "                elif key + '.jpeg' in self.image_dict:\n",
    "                    key = key + '.jpeg'\n",
    "                elif key + '.png' in self.image_dict:\n",
    "                    key = key + '.png'\n",
    "\n",
    "        # If still not found, raise error\n",
    "        if key not in self.image_dict:\n",
    "            raise KeyError(f\"Image ID {isic_id_raw} not found in image_dict.\")\n",
    "\n",
    "        img_path = self.image_dict[key]\n",
    "        \n",
    "        # Open image and convert to RGB\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        # Apply transforms if defined\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # Convert tabular features to tensors\n",
    "        new_cat_columns = torch.tensor(row[self.new_cat_columns].values.astype(float)).float()\n",
    "        cont = torch.tensor(row[self.cont_names].values.astype(float)).float()\n",
    "        y = torch.tensor(row[self.y_col]).long()\n",
    "\n",
    "        return img, new_cat_columns, cont, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa79827",
   "metadata": {},
   "source": [
    "# Combine image and tabular data into a DataBlock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8996f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from fastai.tabular.all import TabularPandas, get_emb_sz, TabularModel, Learner, CrossEntropyLossFlat, accuracy\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    " \n",
    "\n",
    "# Stratified split\n",
    "def stratified_splitter(df, valid_pct=0.25, seed=42):\n",
    "    train_indices, valid_indices = train_test_split(\n",
    "        df.index,\n",
    "        test_size=valid_pct,\n",
    "        stratify=df[y_col],  # stratify by target column\n",
    "        random_state=seed\n",
    "    )\n",
    "    return train_indices, valid_indices\n",
    "\n",
    "# Perform the split\n",
    "train_indices, valid_indices = stratified_splitter(df)\n",
    "\n",
    "# Create train and validation dataframes\n",
    "train_df = df.iloc[train_indices]\n",
    "valid_df = df.iloc[valid_indices]\n",
    "\n",
    "# Define the datasets\n",
    "train_dataset = ImageTabDataset(train_df,images, new_cat_columns, cont_names, y_col)\n",
    "valid_dataset = ImageTabDataset(valid_df,images, new_cat_columns, cont_names, y_col)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# Create a DataLoaders object\n",
    "dls = DataLoaders(train_loader, valid_loader)\n",
    "\n",
    "# Manually get embedding sizes\n",
    "def get_emb_szs(df, new_cat_columns):\n",
    "    return [(df[col].nunique() + 1, min(50, (df[col].nunique() + 1) // 2)) for col in new_cat_columns]\n",
    "\n",
    "# Calculate embedding sizes\n",
    "emb_szs = get_emb_szs(train_df, new_cat_columns)\n",
    "n_cont = len(cont_names)\n",
    "out_sz = len(train_df[y_col].unique())\n",
    "\n",
    "# Define custom model\n",
    "class ImageTabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, ps=0.5):\n",
    "        super().__init__()\n",
    "        # Initialize ResNet50 without pre-trained weights\n",
    "        self.cnn = models.resnet50(weights=None)  # Use weights=None\n",
    "        \n",
    "        # Load custom weights\n",
    "        self.cnn.load_state_dict(torch.load('/home/webadmin/Desktop/ISIC24_Skin_Cancer_Detection/Fastai/resnet50-11ad3fa6.pth'))\n",
    "        \n",
    "        # Adjust the final layer if needed\n",
    "        num_ftrs = self.cnn.fc.in_features\n",
    "        self.cnn.fc = nn.Linear(num_ftrs, out_sz)  # Set the number of output features\n",
    "        \n",
    "        # Initialize the tabular model\n",
    "        self.tab_net = TabularModel(emb_szs, n_cont, out_sz, layers, ps)\n",
    "        \n",
    "        # Define the head that combines image and tabular outputs\n",
    "        self.head = nn.Linear(out_sz * 2, out_sz)  # Adjust as needed\n",
    "\n",
    "    def forward(self, x_img, x_cat, x_cont):\n",
    "        if x_cat.dtype != torch.long:\n",
    "            x_cat = x_cat.long()\n",
    "        \n",
    "        img_out = self.cnn(x_img)\n",
    "        tab_out = self.tab_net(x_cat, x_cont)\n",
    "        combined = torch.cat([img_out, tab_out], dim=1)\n",
    "        return self.head(combined)\n",
    "\n",
    "# Create the model\n",
    "model = ImageTabularModel(emb_szs, n_cont, out_sz, layers=[512, 256, 128], ps=0.5).to(device)\n",
    "\n",
    "# Make the model parallel\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "# Create Learner\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994b4241",
   "metadata": {},
   "source": [
    "Here I split the data into train and validation sets while keeping the class balance. Then I created datasets and DataLoaders for both image and tabular features.\n",
    "\n",
    "I set up embedding sizes for categorical features so the model can handle them better.\n",
    "\n",
    "The model has two parts: ResNet50 for images and a tabular network for metadata. I combine both outputs and pass them through a final layer to get predictions.\n",
    "\n",
    "Finally, I wrapped everything in a fastai Learner to make training easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6959e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your model file\n",
    "model_path_out = Path('/kaggle/working/models/resnet50_full')\n",
    "model_path_in = Path('/kaggle/input/resnet50/pytorch/resnet-3-epochs/1/resnet50_full.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cf0ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the learning rate\n",
    "#learn.lr_find(suggest_funcs=(slide, valley))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6f1b930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>25:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>0.999033</td>\n",
       "      <td>25:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nif not model_path_in.exists():\\n    # Model does not exist, so train and save the model\\n    learn.fit_one_cycle(3, lr_max=custom_lr)\\n    learn.save(model_path_out.stem)\\nelse:\\n    # Model exists, so load, fine-tune, and save it\\n    learn.load(model_path_in.stem)\\n    learn.fine_tune(1)\\n    learn.save(model_path_out.stem)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model file exists\n",
    "#Define the number of epochs\n",
    "numb_epochs=3\n",
    "\n",
    "# Define custom learning rate\n",
    "custom_lr =0.3\n",
    "learn.fine_tune(1)\n",
    "'''\n",
    "if not model_path_in.exists():\n",
    "    # Model does not exist, so train and save the model\n",
    "    learn.fit_one_cycle(3, lr_max=custom_lr)\n",
    "    learn.save(model_path_out.stem)\n",
    "else:\n",
    "    # Model exists, so load, fine-tune, and save it\n",
    "    learn.load(model_path_in.stem)\n",
    "    learn.fine_tune(1)\n",
    "    learn.save(model_path_out.stem)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7982e8c1",
   "metadata": {},
   "source": [
    "The number of epochs and a custom learning rate for training and fine-tune the model for 1 epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7c6326",
   "metadata": {},
   "source": [
    "Output EXP:     \n",
    "The training ran for 1 epoch and the results look really good. The training loss and validation loss are both very low, which means the model is fitting the data well. The accuracy is almost 99.9%, showing that the model is making correct predictions on nearly all validation samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4286ce4b",
   "metadata": {},
   "source": [
    "# Test part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eff6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/home/webadmin/Desktop/isic/\"\n",
    "TEST_HDF = f'{ROOT_DIR}/test-image.hdf5'\n",
    "TEST_CSV = f'{ROOT_DIR}/test-metadata.csv'\n",
    "\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "\n",
    "#Apply to df\n",
    "df_test, _= process_data(df_test,cat_names)  \n",
    "\n",
    "# Ensure the test set has the same dummy variable columns as the training set\n",
    "for col in new_cat_columns:\n",
    "    if col not in df_test:\n",
    "        df_test[col] = 0\n",
    "\n",
    "# Create a list of columns from the training set excluding 'target'\n",
    "train_columns = [col for col in df.columns if col != 'target']\n",
    "\n",
    "# Reorder the test set columns to match the training set columns (excluding 'target')\n",
    "df_test = df_test[train_columns]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e4802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Function to fetch images from an HDF5 file by trying multiple possible keys and formats\n",
    "def _fetch_h5_image(fp, isic_id):\n",
    "    \"\"\"\n",
    "    Try different naming variants and HDF5 groups to find the image:\n",
    "      - Variants: 'ISIC_xxxxxx', 'ISIC_xxxxxx.jpg/.jpeg/.png'\n",
    "      - Groups: 'oversampled_images', 'images', 'image', 'train_images', 'train', 'test', or root\n",
    "    Returns a PIL.Image in RGB format.\n",
    "    \"\"\"\n",
    "    raw = str(isic_id).strip()\n",
    "    stem = raw.rsplit('.', 1)[0]  # remove extension if present\n",
    "    name_candidates = [stem, stem + '.jpg', stem + '.jpeg', stem + '.png']\n",
    "    group_candidates = ['oversampled_images', 'images', 'image', 'train_images', 'train', 'test', None]\n",
    "\n",
    "    for grp in group_candidates:\n",
    "        if grp is not None and grp not in fp:\n",
    "            continue\n",
    "        node = fp[grp] if grp is not None else fp\n",
    "        for name in name_candidates:\n",
    "            if name in node:\n",
    "                ds = node[name]\n",
    "                try:\n",
    "                    arr = ds[()]  # dataset numpy array or raw bytes\n",
    "                except Exception:\n",
    "                    # If it’s a group with a child dataset\n",
    "                    kids = list(ds.keys())\n",
    "                    if not kids: \n",
    "                        continue\n",
    "                    arr = ds[kids[0]][()]\n",
    "\n",
    "                if isinstance(arr, (bytes, bytearray)):  \n",
    "                    # Decode image if stored as raw bytes\n",
    "                    return Image.open(BytesIO(arr)).convert('RGB')\n",
    "                else:                                   \n",
    "                    # If stored as numpy array (H,W,3) or (3,H,W)\n",
    "                    if arr.ndim == 3 and arr.shape[0] in (1,3) and arr.shape[0] != arr.shape[-1]:\n",
    "                        arr = np.moveaxis(arr, 0, -1)   # convert CHW → HWC\n",
    "                    return Image.fromarray(arr).convert('RGB')\n",
    "    # If no match found, raise error with top-level keys shown\n",
    "    tops = list(fp.keys())\n",
    "    raise KeyError(f\"{raw} not found in HDF5. Top-level keys: {tops[:8]}{'...' if len(tops)>8 else ''}\")\n",
    "\n",
    "\n",
    "# Dataset class for combining test images (from HDF5) with tabular metadata\n",
    "class CombinedDataset_test(Dataset):\n",
    "    def __init__(self, df, file_hdf, cat_names, cont_names, transforms=None, target_size=(137, 137)):\n",
    "        self.df = df\n",
    "        self.fp_hdf = h5py.File(file_hdf, mode=\"r\")   \n",
    "        self.isic_ids = df['isic_id'].values          \n",
    "        self.transforms = transforms\n",
    "        self.target_size = target_size\n",
    "\n",
    "        self.cat_names = cat_names\n",
    "        self.cont_names = cont_names\n",
    "\n",
    "        # Convert categorical columns to integer codes\n",
    "        for cat in cat_names:\n",
    "            if cat in self.df.columns:\n",
    "                self.df[cat] = self.df[cat].astype('category').cat.codes\n",
    "\n",
    "        # Convert all other columns to numeric (except isic_id)\n",
    "        for col in df.columns:\n",
    "            if col not in cat_names + ['isic_id']:\n",
    "                self.df[col] = pd.to_numeric(self.df[col], errors='coerce')\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return number of rows in dataframe\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get image ID\n",
    "        isic_id = self.isic_ids[index]\n",
    "\n",
    "        # Fetch image from HDF5 using robust lookup\n",
    "        img = _fetch_h5_image(self.fp_hdf, isic_id)\n",
    "        img = img.resize(self.target_size, Image.LANCZOS)\n",
    "\n",
    "        # Apply transforms (e.g. resize, tensor conversion)\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        # Get tabular data for this row\n",
    "        row = self.df.iloc[index]\n",
    "        cat_data  = row[self.cat_names]      \n",
    "        cont_data = row[self.cont_names]    \n",
    "\n",
    "        # Convert to tensors\n",
    "        cat_tensor  = torch.tensor(cat_data.values.astype(int),    dtype=torch.long)\n",
    "        cont_tensor = torch.tensor(cont_data.values.astype(float), dtype=torch.float32)\n",
    "        y = torch.tensor(0, dtype=torch.long)\n",
    "\n",
    "        return img, cat_tensor, cont_tensor, y\n",
    "\n",
    "    def __del__(self):\n",
    "        # Safely close HDF5 file when object is deleted\n",
    "        try:\n",
    "            self.fp_hdf.close()\n",
    "        except Exception:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f7bc02",
   "metadata": {},
   "source": [
    "Here I set up a helper function to fetch images directly from the HDF5 file. Since the images can be stored with different names or in different groups, the function tries multiple options until it finds the right one and then converts it into an RGB image.\n",
    "\n",
    "I also created a custom dataset class for the test set. This class loads images from the HDF5 file and pairs them with the patient metadata. The categorical columns are converted into numeric codes, and continuous columns are kept as numbers. For each sample, it returns the image, categorical features, continuous features, and a dummy target (since the test set doesn’t have labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e6a9d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Define the transformations\n",
    "data_transforms = T.Compose([\n",
    "    T.Resize((137, 137)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'valid_batch_size': 64,  # Batch size for validation\n",
    "}\n",
    "\n",
    "# Create the combined dataset\n",
    "combined_dataset = CombinedDataset_test(df_test, TEST_HDF, new_cat_columns, cont_names, transforms=data_transforms)\n",
    "\n",
    "# Define DataLoader\n",
    "test_loader = DataLoader(combined_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                         num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "learn.model.eval()\n",
    "\n",
    "# Run predictions on the test DataLoader\n",
    "preds, targs = learn.get_preds(dl=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a94bc6",
   "metadata": {},
   "source": [
    "Preparing the test dataset. The images are resized and converted to tensors, and then combined with the metadata using the custom dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7243576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Initialize lists to collect predictions and ids\n",
    "all_probs_class_1 = []\n",
    "all_isic_ids = []\n",
    "\n",
    "# Example function to handle probabilities\n",
    "def process_probabilities(probabilities):\n",
    "    # Replace NaN values with 0\n",
    "    probabilities = np.nan_to_num(probabilities, nan=0.0)\n",
    "    \n",
    "    # Ensure probabilities are within the range [0, 1]\n",
    "    probabilities = np.clip(probabilities, 0, 1)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "# Get predictions from the DataLoader\n",
    "with torch.no_grad():\n",
    "    # Obtain predictions for the entire test set\n",
    "    logits, _ = learn.get_preds(dl=test_loader)  # The second output is targets, which is ignored\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "    # Extract the probabilities for class ID 1\n",
    "    prob_class_1 = probabilities[:, 1].detach().cpu().numpy()\n",
    "    \n",
    "    #process probabilities to ensure they are between 0 and 1\n",
    "    prob_class_1 = process_probabilities(prob_class_1)\n",
    "    \n",
    "    # Collect the probabilities and ids\n",
    "    all_probs_class_1.extend(prob_class_1)\n",
    "    all_isic_ids.extend(combined_dataset.isic_ids[:len(prob_class_1)])  # Use the dataset directly\n",
    "\n",
    "# Convert lists to arrays or DataFrame if needed\n",
    "import pandas as pd\n",
    "results = pd.DataFrame({\n",
    "    'isic_id': all_isic_ids,\n",
    "    'target': all_probs_class_1\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb4e6f",
   "metadata": {},
   "source": [
    "Here I ran the model on the test dataset and collected predictions. The raw outputs (logits) were converted into probabilities using softmax. I focused on the probability of class 1 (melanoma) and made sure values were cleaned so they stay between 0 and 1.\n",
    "\n",
    "For each test image, I stored both the probability and its ID. Finally, I combined everything into a DataFrame with two columns: isic_id and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d9196fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "133ad5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657.jpg</td>\n",
       "      <td>0.269085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729.jpg</td>\n",
       "      <td>0.269083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740.jpg</td>\n",
       "      <td>0.269101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            isic_id    target\n",
       "0  ISIC_0015657.jpg  0.269085\n",
       "1  ISIC_0015729.jpg  0.269083\n",
       "2  ISIC_0015740.jpg  0.269101"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70328d4",
   "metadata": {},
   "source": [
    "isic_id - the unique image ID (with .jpg extension) that matches the skin image in the dataset.     \n",
    "target - the predicted probability that this image belongs to class 1 (melanoma).    \n",
    "\n",
    "The values in the target column are probabilities between 0 and 1:     \n",
    "\n",
    "A value closer to 1.0 means the model is highly confident the image is melanoma.\n",
    "A value closer to 0.0 means the model is confident it’s not melanoma.\n",
    "Values around 0.5 mean the model is uncertain.\n",
    "\n",
    "For example:                \n",
    "ISIC_0015657.jpg - 0.269 - about a 27% chance of melanoma.   \n",
    "\n",
    "ISIC_0015729.jpg - 0.269 - again 27% chance.\n",
    "\n",
    "ISIC_0015740.jpg - 0.269 - similar probability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38_PT_and_TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
