{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1250c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastcore.parallel import *\n",
    "import fastai\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    " \n",
    "\n",
    "# Set paths\n",
    "path = Path(\"/kaggle/input/isic-2024-challenge/\")\n",
    "train_metadata_path = path / 'train-metadata.csv'\n",
    "images_path = path / 'train-image/image/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67134930",
   "metadata": {},
   "source": [
    "# Preparing metadata file and merge with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4254c6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple']\n",
      "Continuous columns: ['age_approx', 'clin_size_long_diam_mm', 'tbp_lv_A', 'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext', 'tbp_lv_C', 'tbp_lv_Cext', 'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L', 'tbp_lv_Lext', 'tbp_lv_areaMM2', 'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', 'tbp_lv_deltaA', 'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_deltaLB', 'tbp_lv_deltaLBnorm', 'tbp_lv_eccentricity', 'tbp_lv_minorAxisMM', 'tbp_lv_nevi_confidence', 'tbp_lv_norm_border', 'tbp_lv_norm_color', 'tbp_lv_perimeterMM', 'tbp_lv_radial_color_std_max', 'tbp_lv_stdL', 'tbp_lv_stdLExt', 'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle', 'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z']\n",
      "Target column: target\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "#  Step 1: Define the full path to the CSV file\n",
    "train_metadata_path = Path(\"C:/Users/Yashwanth/isic/train-metadata.csv\")\n",
    "\n",
    "#  Step 2: Load the metadata CSV\n",
    "df = pd.read_csv(train_metadata_path, low_memory=False)\n",
    "\n",
    "#  Step 3: Drop unnecessary columns\n",
    "columns_to_drop = [\n",
    "    'copyright_license', 'attribution', 'image_type', 'iddx_1', 'iddx_2', 'iddx_3', 'iddx_4',\n",
    "    'iddx_5', 'iddx_full', 'mel_mitotic_index', 'mel_thick_mm', 'tbp_tile_type', \n",
    "    'tbp_lv_dnn_lesion_confidence', 'lesion_id'\n",
    "]\n",
    "\n",
    "df.drop(columns=columns_to_drop, inplace=True, errors='ignore')  # `errors='ignore'` avoids crash if column missing\n",
    "\n",
    "#  Step 4: Define categorical and continuous feature columns\n",
    "cat_names = ['sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple']\n",
    "cont_names = [x for x in df.columns if x not in cat_names + ['target', 'isic_id', 'patient_id'] + columns_to_drop]\n",
    "\n",
    "#  Step 5: Define target and image ID columns\n",
    "y_col = 'target'\n",
    "image_col = 'isic_id'\n",
    "\n",
    "# Preview\n",
    "print(\"Categorical columns:\", cat_names)\n",
    "print(\"Continuous columns:\", cont_names)\n",
    "print(\"Target column:\", y_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fbff428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, cat_names):\n",
    "    \n",
    "    \n",
    "    # Drop columns \n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "    \n",
    "    # Add number of pictures for each patient\n",
    "    df['numb_pic'] = df.groupby('patient_id')['patient_id'].transform('count')\n",
    "    \n",
    "    # Fill missing values with the mode\n",
    "    if 'age_approx' in df.columns:\n",
    "        mode_age = df['age_approx'].mode()[0]\n",
    "        df['age_approx'] = df['age_approx'].fillna(mode_age)\n",
    "    \n",
    "    if 'sex' in df.columns:\n",
    "        mode_sex = df['sex'].mode()[0]\n",
    "        df['sex'] = df['sex'].fillna(mode_sex)\n",
    "    \n",
    "    # Convert categorical columns to dummies\n",
    "    df = pd.get_dummies(df, columns=cat_names, prefix=cat_names)\n",
    "    \n",
    "    # Get new categorical column names\n",
    "    new_cat_columns = [col for col in df.columns if any(col.startswith(name + '_') for name in cat_names)]\n",
    "    \n",
    "    # Ensure 'isic_id' in df has the correct file extension\n",
    "    # if 'isic_id' in df.columns:\n",
    "    #     df['isic_id'] = df['isic_id'].apply(lambda x: x.strip() + '.jpg')\n",
    "    \n",
    "    return df, new_cat_columns\n",
    "\n",
    "#Apply to df\n",
    "df, new_cat_columns= process_data(df,cat_names)  \n",
    "\n",
    "# Load images and create DataFrame\n",
    "images = get_image_files(images_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b633b9",
   "metadata": {},
   "source": [
    "# Create a custom dataset that includes both image and tabular data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97bfb542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "\n",
    "class ImageTabDataset(Dataset):\n",
    "    def __init__(self, df, image_files, new_cat_columns, cont_names, y_col, img_size=(137, 137), transform=None):\n",
    "        self.df = df\n",
    "        self.image_files = [Path(img) for img in image_files]\n",
    "        self.new_cat_columns = new_cat_columns\n",
    "        self.cont_names = cont_names\n",
    "        self.y_col = y_col\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize(self.img_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        self.image_dict = {img.stem: img for img in self.image_files}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Verify that self.df is a DataFrame\n",
    "        if not isinstance(self.df, pd.DataFrame):\n",
    "            raise TypeError(f\"Expected self.df to be a DataFrame, but got {type(self.df).__name__}\")\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "        isic_id = row['isic_id']\n",
    "        if isic_id not in self.image_dict:\n",
    "            raise KeyError(f\"Image ID {isic_id} not found in image_dict.\")\n",
    "        img_path = self.image_dict[isic_id]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        new_cat_columns = torch.tensor(row[self.new_cat_columns].values.astype(float)).float()\n",
    "        cont = torch.tensor(row[self.cont_names].values.astype(float)).float()\n",
    "        y = torch.tensor(row[self.y_col]).long()\n",
    "\n",
    "        return img, new_cat_columns, cont, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb688e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8996f0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6959e3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
