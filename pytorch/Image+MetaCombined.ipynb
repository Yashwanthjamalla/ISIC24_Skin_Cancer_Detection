{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68091,
     "status": "ok",
     "timestamp": 1722644910198,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "gyTMdE-0nfLF",
    "outputId": "2e49ed56-9862-4180-9555-b1a80666bf4c"
   },
   "outputs": [],
   "source": [
    "!pip install -qq timm\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3849,
     "status": "ok",
     "timestamp": 1722644914041,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "kP0NkFBpfpYr"
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "set_seed(42)\n",
    "\n",
    "from fastcore.parallel import *\n",
    "from fastai.data.core import *\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1722644914041,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "Ytx7nP51hgul"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10901,
     "status": "ok",
     "timestamp": 1722644924939,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "Vr3vC3Clh1kB",
    "outputId": "ae2aac5d-53c6-4940-a99a-023093a0db9f"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/webadmin/Desktop/isic/train-metadata.csv')\n",
    "\n",
    "df['isic_id'] = [name + '.jpg' for name in df['isic_id']]\n",
    "df = df.set_index('isic_id')\n",
    "\n",
    "#Calculate weights for the umbalanced data:\n",
    "# Step 1: Count the number of samples for each class\n",
    "class_counts = df['target'].value_counts().sort_index()\n",
    "\n",
    "# Step 2: Calculate class weights\n",
    "class_weights = class_counts.sum() / (len(class_counts) * class_counts)\n",
    "\n",
    "# Step 3: Normalize the class weights\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "\n",
    "# Step 4: Convert to PyTorch tensor\n",
    "class_weights = torch.tensor(class_weights.values, dtype=torch.float32)\n",
    "\n",
    "# Print the class weights\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1722644924939,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "bH08mzJ7iJdC"
   },
   "outputs": [],
   "source": [
    "#later we can try to include diagnosis as well\n",
    "#def get_diagnosis(p): return df.loc[p.name, 'iddx_full']\n",
    "\n",
    "def get_target(p): return df.loc[p.name, 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30473,
     "status": "ok",
     "timestamp": 1722644955409,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "IMxSVNCyiPgS"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "images_path= Path('/home/webadmin/Desktop/isic/image')\n",
    "\n",
    "%timeit\n",
    "dls = DataBlock(\n",
    "    blocks=(ImageBlock,CategoryBlock),\n",
    "    n_inp=1,\n",
    "    get_items=get_image_files,\n",
    "    get_y = [get_target],\n",
    "    splitter=RandomSplitter(0.2, seed=42),\n",
    "    item_tfms=Resize(125, method='squish'),\n",
    "    batch_tfms=aug_transforms(size=128, min_scale=0.75)\n",
    ").dataloaders(images_path,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "executionInfo": {
     "elapsed": 1438,
     "status": "ok",
     "timestamp": 1722644956833,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "eFxIn4m0izWR",
    "outputId": "f9ee8e0a-47c6-47a4-d150-cb7ceb54b2d5"
   },
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1722644956833,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "-Pw6fjz6i3yo"
   },
   "outputs": [],
   "source": [
    "def target_err(inp,target): return error_rate(inp,target)\n",
    "#def target_loss(inp,target): return F.cross_entropy(inp,target,weight=class_weights)\n",
    "def target_loss(inp, target):\n",
    "    device = inp.device  # Get the device from input tensor\n",
    "    current_class_weights = class_weights.to(device)  # Move class weights to the same device\n",
    "    return F.cross_entropy(inp, target, weight=current_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188,
     "referenced_widgets": [
      "67d2840a1bd64bdaafb7575d850fff09",
      "57522bbda8eb483187f9988cc0a7c803",
      "879515f60bc74d6d8797ad2a9540a71e",
      "459fc3fb985f4da98fc961712a972ab0",
      "b3c5004a2555483d9beb0008a32b046b",
      "88179705572944dc8a9f4352deee2b51",
      "b32da98f122f454485176021d99e2ca3",
      "dd1c4dee052a467fbcf4d0f1350d1553",
      "d91a0eda214544189e4244890a4354ac",
      "ce1ce016c8c64351a7ed0c1535c3c563",
      "f6017ae823dc4b8cac3814129d36d9d9"
     ]
    },
    "executionInfo": {
     "elapsed": 9634,
     "status": "ok",
     "timestamp": 1722644966463,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "0jjj71w5i6Uo",
    "outputId": "0b0330cf-3fc3-436d-ac3a-2412df8f03ea"
   },
   "outputs": [],
   "source": [
    "arch = 'convnext_small_in22k'\n",
    "#learn = vision_learner(dls, arch, loss_func=target_loss, metrics=target_err, n_out=7).to_fp16()\n",
    "lr = 0.01\n",
    "\n",
    "# Custom loss function with class weights on the correct device\n",
    "def target_loss(inp, target):\n",
    "    device = inp.device  # Get the device from input tensor\n",
    "    current_class_weights = class_weights.to(device)  # Move class weights to the same device\n",
    "    return F.cross_entropy(inp, target, weight=current_class_weights)\n",
    "\n",
    "# Create the learner\n",
    "learn = vision_learner(dls, arch, loss_func=target_loss, metrics=target_err,n_out=2).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 5634155,
     "status": "ok",
     "timestamp": 1722651853175,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "QL4WCMOQpLc2",
    "outputId": "4b31717b-f68c-4377-aea1-c10c51f0fd8f"
   },
   "outputs": [],
   "source": [
    "model_path = Path('/home/webadmin/Desktop/isic/convnext_small_in22k_model.pkl')\n",
    "\n",
    "if not model_path.exists():\n",
    "    # Model does not exist, so train and save the model\n",
    "    learn.fit_one_cycle(4, lr_max=1e-4)\n",
    "    learn.save(model_path.stem)\n",
    "else:\n",
    "    # Model exists, so load, fine-tune, and save it\n",
    "    learn.load(model_path.stem)\n",
    "    learn.fine_tune(4, lr_max=1e-4)\n",
    "    learn.save(model_path.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "save_dir = Path(\"/home/webadmin/Desktop/isic/models\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)  # make the folder if missing\n",
    "learn.export(save_dir / \"my_model.pkl\")      # export the whole Learner\n",
    "print(\"Saved to:\", save_dir / \"my_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1636,
     "status": "ok",
     "timestamp": 1722652097734,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "pMVWHF1-D8PR"
   },
   "outputs": [],
   "source": [
    "#Save the trained model, i think it takes long time\n",
    "learn.export('/home/webadmin/Desktop/isic/models/my_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxRHYgKxEYFf"
   },
   "source": [
    "**TEST PART**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1722652191283,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "P0ZuVkoPEUr6"
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/home/webadmin/Desktop/isic/\"\n",
    "TEST_HDF = f'{ROOT_DIR}/test-image.hdf5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1722652236441,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "W04MrwAtEnHk"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, file_hdf, transforms=None, target_size=(125,125)):\n",
    "        self.fp_hdf = h5py.File(file_hdf, mode=\"r\")\n",
    "        self.image_ids = list(self.fp_hdf.keys())\n",
    "        self.transforms = transforms\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.image_ids[index]\n",
    "        img = Image.open(BytesIO(self.fp_hdf[img_id][()]))\n",
    "\n",
    "        # Resize the image\n",
    "        img = img.resize(self.target_size, Image.LANCZOS)\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        # Return image and a dummy target\n",
    "        return img, 0  # Dummy target (could be any value between 0 and 1)\n",
    "\n",
    "# Define your configuration\n",
    "CONFIG = {\n",
    "    'valid_batch_size': 32\n",
    "}\n",
    "\n",
    "\n",
    "data_transforms = T.Compose([\n",
    "    T.Resize((125, 125)),  # Resize images to a fixed size\n",
    "    T.ToTensor(),  # Convert PIL Image to tensor\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1722652255791,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "ZKhWxmfBEylJ",
    "outputId": "1332d9dd-ac5f-4af3-d761-b5fcd13e0841"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define transformations directly\n",
    "data_transforms = T.Compose([\n",
    "    T.Resize((125, 125)),  # Resize images to a fixed size\n",
    "    T.ToTensor(),  # Convert PIL Image to tensor\n",
    "])\n",
    "\n",
    "# Create the dataset and DataLoader\n",
    "test_dataset = ISICDataset(file_hdf=TEST_HDF, transforms=data_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['valid_batch_size'],\n",
    "                        num_workers=4, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1722652290240,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "H0b7D4M8E7Vu",
    "outputId": "bff9a5e6-eb92-4799-c0f1-8e8bd0744efc"
   },
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "learn.model.eval()\n",
    "\n",
    "# Run predictions on the test DataLoader\n",
    "preds, _ = learn.get_preds(dl=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1722652565029,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "PqAYdqTvE_Wy",
    "outputId": "848e3532-fcc4-44c4-c127-fa66f5f56ead"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Initialize lists to collect probabilities and IDs\n",
    "all_probs_class_1 = []\n",
    "all_isic_ids = []\n",
    "\n",
    "\n",
    "# Iterate over DataLoader\n",
    "with torch.no_grad():\n",
    "    for imgs, _ in test_loader:\n",
    "        # Forward pass to get logits\n",
    "        imgs = imgs.cuda()\n",
    "        logits = learn.model(imgs)  # Get model outputs directly\n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "        # Extract the probabilities for class ID 1\n",
    "        prob_class_1 = probabilities[:, 1].detach().cpu().numpy()\n",
    "\n",
    "        # Collect the probabilities\n",
    "        all_probs_class_1.extend(prob_class_1)\n",
    "\n",
    "        # Collect IDs\n",
    "        batch_ids = [test_dataset.image_ids[i] for i in range(len(prob_class_1))]\n",
    "        all_isic_ids.extend(batch_ids)\n",
    "\n",
    "# Convert lists to arrays or DataFrame if needed\n",
    "import numpy as np\n",
    "all_probs_class_1 = np.array(all_probs_class_1)\n",
    "all_isic_ids = np.array(all_isic_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 172,
     "status": "ok",
     "timestamp": 1722652586114,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "S0izWpYQGD6i"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'isic_id': all_isic_ids,\n",
    "    'prob_class_1': all_probs_class_1\n",
    "})\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1722652598881,
     "user": {
      "displayName": "Sarasij Maitra",
      "userId": "00298515063046113871"
     },
     "user_tz": 360
    },
    "id": "8_JPZHdfGJf5",
    "outputId": "9f3494f9-44ca-43ce-9340-af4ffc9e4e74"
   },
   "outputs": [],
   "source": [
    "submission_df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMnOIhOyvHPqfc/flIsf+ti",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "azureml_py38_PT_and_TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
