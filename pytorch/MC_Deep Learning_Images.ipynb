{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398378ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "#import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "import torchvision\n",
    "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "from datasets import load_dataset\n",
    "from torcheval.metrics.functional import binary_auroc\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "630911e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/Users/Yashwanth/isic\"\n",
    "TRAIN_DIR = f'{ROOT_DIR}/train-image/image'\n",
    "\n",
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"n_samples_train\":10000,\n",
    "    \"n_samples_val\":10000, \n",
    "    \"epochs\": 50,\n",
    "    \"img_size\": 384,\n",
    "    \"model_name\": \"tf_efficientnet_b0_ns\",\n",
    "    \"checkpoint_path\" : \"/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b0/1/tf_efficientnet_b0_aa-827b6e33.pth\",\n",
    "    \"train_batch_size\": 400,\n",
    "    \"valid_batch_size\": 400,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"scheduler\": 'CosineAnnealingLR',\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"T_max\": 500,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"fold\" : 4,\n",
    "    \"n_fold\": 5,\n",
    "    \"n_accumulate\": 1,\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}\n",
    "\n",
    "BEST_WEIGHT = 'v2_AUROC0.9324_Loss0.0043_epoch22_lossauroc.pth'#'v2_AUROC0.8736_Loss0.0158_epoch12_lossauroc.pth'#'v2_AUROC0.6942_Loss0.2311_epoch26.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8390d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG['device'] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")#torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe1ad6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=CONFIG['seed']\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e4710",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a7bf7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yashwanth\\AppData\\Local\\Temp\\ipykernel_25464\\1934611744.py:1: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(ROOT_DIR+\"/train-metadata.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>sex</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>image_type</th>\n",
       "      <th>tbp_tile_type</th>\n",
       "      <th>tbp_lv_A</th>\n",
       "      <th>...</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>iddx_full</th>\n",
       "      <th>iddx_1</th>\n",
       "      <th>iddx_2</th>\n",
       "      <th>iddx_3</th>\n",
       "      <th>iddx_4</th>\n",
       "      <th>iddx_5</th>\n",
       "      <th>mel_mitotic_index</th>\n",
       "      <th>mel_thick_mm</th>\n",
       "      <th>tbp_lv_dnn_lesion_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015670</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_1235828</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>3.04</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>20.244422</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.517282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015845</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_8170065</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>1.10</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>31.712570</td>\n",
       "      <td>...</td>\n",
       "      <td>IL_6727506</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.141455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015864</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_6724798</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>3.40</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>22.575830</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.804040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0015902</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_4111386</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>3.22</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>14.242329</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.989998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0024200</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_8313778</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>2.73</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>24.725520</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.442510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id  target  patient_id  age_approx   sex anatom_site_general  \\\n",
       "0  ISIC_0015670       0  IP_1235828        60.0  male     lower extremity   \n",
       "1  ISIC_0015845       0  IP_8170065        60.0  male           head/neck   \n",
       "2  ISIC_0015864       0  IP_6724798        60.0  male     posterior torso   \n",
       "3  ISIC_0015902       0  IP_4111386        65.0  male      anterior torso   \n",
       "4  ISIC_0024200       0  IP_8313778        55.0  male      anterior torso   \n",
       "\n",
       "   clin_size_long_diam_mm          image_type tbp_tile_type   tbp_lv_A  ...  \\\n",
       "0                    3.04  TBP tile: close-up     3D: white  20.244422  ...   \n",
       "1                    1.10  TBP tile: close-up     3D: white  31.712570  ...   \n",
       "2                    3.40  TBP tile: close-up        3D: XP  22.575830  ...   \n",
       "3                    3.22  TBP tile: close-up        3D: XP  14.242329  ...   \n",
       "4                    2.73  TBP tile: close-up     3D: white  24.725520  ...   \n",
       "\n",
       "    lesion_id  iddx_full  iddx_1  iddx_2  iddx_3  iddx_4  iddx_5  \\\n",
       "0         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
       "1  IL_6727506     Benign  Benign     NaN     NaN     NaN     NaN   \n",
       "2         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
       "3         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
       "4         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   mel_mitotic_index  mel_thick_mm  tbp_lv_dnn_lesion_confidence  \n",
       "0                NaN           NaN                     97.517282  \n",
       "1                NaN           NaN                      3.141455  \n",
       "2                NaN           NaN                     99.804040  \n",
       "3                NaN           NaN                     99.989998  \n",
       "4                NaN           NaN                     70.442510  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>sex</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>image_type</th>\n",
       "      <th>tbp_tile_type</th>\n",
       "      <th>tbp_lv_A</th>\n",
       "      <th>tbp_lv_Aext</th>\n",
       "      <th>...</th>\n",
       "      <th>tbp_lv_radial_color_std_max</th>\n",
       "      <th>tbp_lv_stdL</th>\n",
       "      <th>tbp_lv_stdLExt</th>\n",
       "      <th>tbp_lv_symm_2axis</th>\n",
       "      <th>tbp_lv_symm_2axis_angle</th>\n",
       "      <th>tbp_lv_x</th>\n",
       "      <th>tbp_lv_y</th>\n",
       "      <th>tbp_lv_z</th>\n",
       "      <th>attribution</th>\n",
       "      <th>copyright_license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>IP_6074337</td>\n",
       "      <td>45.0</td>\n",
       "      <td>male</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>2.70</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>22.80433</td>\n",
       "      <td>20.007270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304827</td>\n",
       "      <td>1.281532</td>\n",
       "      <td>2.299935</td>\n",
       "      <td>0.479339</td>\n",
       "      <td>20</td>\n",
       "      <td>-155.06510</td>\n",
       "      <td>1511.222000</td>\n",
       "      <td>113.980100</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-BY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>IP_1664139</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>2.52</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>16.64867</td>\n",
       "      <td>9.657964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.271940</td>\n",
       "      <td>2.011223</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>25</td>\n",
       "      <td>-112.36924</td>\n",
       "      <td>629.535889</td>\n",
       "      <td>-15.019287</td>\n",
       "      <td>Frazer Institute, The University of Queensland...</td>\n",
       "      <td>CC-BY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740</td>\n",
       "      <td>IP_7142616</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>3.16</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>24.25384</td>\n",
       "      <td>19.937380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230742</td>\n",
       "      <td>1.080308</td>\n",
       "      <td>2.705857</td>\n",
       "      <td>0.366071</td>\n",
       "      <td>110</td>\n",
       "      <td>-84.29282</td>\n",
       "      <td>1303.978000</td>\n",
       "      <td>-28.576050</td>\n",
       "      <td>FNQH Cairns</td>\n",
       "      <td>CC-BY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id  patient_id  age_approx     sex anatom_site_general  \\\n",
       "0  ISIC_0015657  IP_6074337        45.0    male     posterior torso   \n",
       "1  ISIC_0015729  IP_1664139        35.0  female     lower extremity   \n",
       "2  ISIC_0015740  IP_7142616        65.0    male     posterior torso   \n",
       "\n",
       "   clin_size_long_diam_mm          image_type tbp_tile_type  tbp_lv_A  \\\n",
       "0                    2.70  TBP tile: close-up        3D: XP  22.80433   \n",
       "1                    2.52  TBP tile: close-up        3D: XP  16.64867   \n",
       "2                    3.16  TBP tile: close-up        3D: XP  24.25384   \n",
       "\n",
       "   tbp_lv_Aext  ...  tbp_lv_radial_color_std_max  tbp_lv_stdL  tbp_lv_stdLExt  \\\n",
       "0    20.007270  ...                     0.304827     1.281532        2.299935   \n",
       "1     9.657964  ...                     0.000000     1.271940        2.011223   \n",
       "2    19.937380  ...                     0.230742     1.080308        2.705857   \n",
       "\n",
       "   tbp_lv_symm_2axis  tbp_lv_symm_2axis_angle   tbp_lv_x     tbp_lv_y  \\\n",
       "0           0.479339                       20 -155.06510  1511.222000   \n",
       "1           0.426230                       25 -112.36924   629.535889   \n",
       "2           0.366071                      110  -84.29282  1303.978000   \n",
       "\n",
       "     tbp_lv_z                                        attribution  \\\n",
       "0  113.980100             Memorial Sloan Kettering Cancer Center   \n",
       "1  -15.019287  Frazer Institute, The University of Queensland...   \n",
       "2  -28.576050                                        FNQH Cairns   \n",
       "\n",
       "   copyright_license  \n",
       "0              CC-BY  \n",
       "1              CC-BY  \n",
       "2              CC-BY  \n",
       "\n",
       "[3 rows x 44 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(ROOT_DIR+\"/train-metadata.csv\")\n",
    "test_df = pd.read_csv(ROOT_DIR+\"/test-metadata.csv\")\n",
    "\n",
    "all_df = pd.concat([train_df, test_df]).reset_index(drop=True)\n",
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = sorted(glob.glob(f\"{TRAIN_DIR}/*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "353ef739",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Images\n",
    "\n",
    "def get_train_file_path(image_id):\n",
    "    return f\"{TRAIN_DIR}/{image_id}.jpg\"\n",
    "\n",
    "def show_im(image_id):\n",
    "    image = mpimg.imread(image_id)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3b3fb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139, 139, 3)\n",
      "(127, 127, 3)\n",
      "(145, 145, 3)\n",
      "(109, 109, 3)\n",
      "(125, 125, 3)\n",
      "(119, 119, 3)\n",
      "(117, 117, 3)\n",
      "(157, 157, 3)\n",
      "(111, 111, 3)\n",
      "(127, 127, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    image = mpimg.imread(train_images[i])\n",
    "    print(image.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7fd904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of images , # of positive cases, # of negative cases, # of patients\n",
      "(401059, 56) 393 400666 (1042,)\n"
     ]
    }
   ],
   "source": [
    "df['image_path'] = df['image_path'].str.replace('\\\\', '/', regex=False)\n",
    "train_images = [p.replace('\\\\', '/') for p in train_images]\n",
    "\n",
    "# --- your original code as-is ---\n",
    "df = train_df.copy()\n",
    "df['image_path'] = df['isic_id'].apply(get_train_file_path)\n",
    "#df['image'] = df['isic_id'].apply(show_im)\n",
    "df = df[ df[\"image_path\"].isin(train_images) ].reset_index(drop=True)\n",
    "\n",
    "print(\"# of images , # of positive cases, # of negative cases, # of patients\")\n",
    "print(df.shape, df.target.sum(), (df[\"target\"] == 0).sum(), df[\"patient_id\"].unique().shape)\n",
    "\n",
    "df_positive = df[df[\"target\"] == 1].reset_index(drop=True)\n",
    "df_negative = df[df[\"target\"] == 0].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7805692",
   "metadata": {},
   "source": [
    "## Start of Deep Learning: Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cebd3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yashwanth\\AppData\\Roaming\\Python\\Python313\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the data augmentation and preprocessing steps for training, validation, and training-test phases.\n",
    "# These transformations help the model generalize better by simulating real-world variations in images.\n",
    "\n",
    "data_transforms = {\n",
    "    \n",
    "    # ---------------------------------------------\n",
    "    # TRAINING TRANSFORMATIONS\n",
    "    # ---------------------------------------------\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.RandomRotate90(p=0.5),   # Random 90° rotation\n",
    "        A.HorizontalFlip(p=0.5),   # Left ↔ right flip\n",
    "        A.VerticalFlip(p=0.5),     # Top ↔ bottom flip\n",
    "        A.Downscale(p=0.25),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.1,\n",
    "            scale_limit=0.15,\n",
    "            rotate_limit=60,\n",
    "            p=0.5\n",
    "        ),\n",
    "        A.HueSaturationValue(\n",
    "            hue_shift_limit=0.2,\n",
    "            sat_shift_limit=0.2,\n",
    "            val_shift_limit=0.2,\n",
    "            p=0.5\n",
    "        ),\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=(-0.1, 0.1),\n",
    "            contrast_limit=(-0.1, 0.1),\n",
    "            p=0.5\n",
    "        ),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "    ], p=1.0),\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------\n",
    "    # VALIDATION TRANSFORMATIONS\n",
    "    # ---------------------------------------------\n",
    "    \"validation\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "    ], p=1.0),\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------\n",
    "    # TRAIN-TEST (MIXED) TRANSFORMATIONS\n",
    "    # ---------------------------------------------\n",
    "    \"train_testing\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        # A.RandomRotate90(p=0.5),  # Disabled optional rotation\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Downscale(p=0.25),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.1,\n",
    "            scale_limit=0.15,\n",
    "            rotate_limit=60,\n",
    "            p=0.5\n",
    "        ),\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.HueSaturationValue(\n",
    "            hue_shift_limit=0.2,\n",
    "            sat_shift_limit=0.2,\n",
    "            val_shift_limit=0.2,\n",
    "            p=0.5\n",
    "        ),\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=(-0.1, 0.1),\n",
    "            contrast_limit=(-0.1, 0.1),\n",
    "            p=0.5\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "    ], p=1.0)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c4d767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, df, phase=\"train\", transforms=None):\n",
    "        # Store how many samples to use and where to start from, based on phase.\n",
    "        # Idea: 'train' and 'train_testing' use the training count after skipping a validation-sized offset.\n",
    "        if phase == 'train':\n",
    "            offset = CONFIG[\"n_samples_val\"]      # skip this many rows at the start for negatives\n",
    "            n_samples = CONFIG[\"n_samples_train\"] # total items the dataset will report\n",
    "        elif phase == 'train_testing':\n",
    "            offset = CONFIG[\"n_samples_val\"]\n",
    "            n_samples = CONFIG[\"n_samples_train\"]\n",
    "        elif phase == 'validation':\n",
    "            offset = 0\n",
    "            n_samples = CONFIG[\"n_samples_val\"]\n",
    "\n",
    "        # Split the dataframe by class label for easy handling\n",
    "        self.df_positive = df[df[\"target\"] == 1].reset_index(drop=True)\n",
    "        self.df_negative = df[df[\"target\"] == 0].reset_index(drop=True)\n",
    "        \n",
    "        # Shuffle negatives once (deterministic with random_state) and then\n",
    "        # take a window: start at 'offset' and keep half of n_samples.\n",
    "        self.df_negative = self.df_negative.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "        self.df_negative = self.df_negative[offset:offset + n_samples // 2]\n",
    "\n",
    "        # Save the transform pipeline and the “length” the dataset should present\n",
    "        self.transforms = transforms\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "        # ----- Prebuild transformed POSITIVE samples -----\n",
    "        # For each positive image, we create multiple augmented versions up front.\n",
    "        # This acts like oversampling + augmentation for the minority/positive class.\n",
    "        self.positive_samples = []\n",
    "        for idx in range(len(self.df_positive)):\n",
    "            img_path = self.df_positive['image_path'].iloc[idx]\n",
    "            img = Image.open(img_path).convert(\"RGB\")   # ensure 3-channel RGB\n",
    "            img_np = np.array(img).copy()               # work with a NumPy array for Albumentations\n",
    "            # Create several variants from the same image\n",
    "            for _ in range(n_samples // (2 * len(self.df_positive))):\n",
    "                transformed_img = self.transforms(image=img_np.copy())[\"image\"]\n",
    "                self.positive_samples.append((transformed_img, 1))\n",
    "\n",
    "        # ----- Prebuild transformed NEGATIVE samples -----\n",
    "        # For each selected negative image, make exactly one transformed version.\n",
    "        self.negative_samples = []\n",
    "        for idx in range(len(self.df_negative)):\n",
    "            img_path = self.df_negative['image_path'].iloc[idx]\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img_np = np.array(img).copy()\n",
    "            transformed_img = self.transforms(image=img_np)[\"image\"]\n",
    "            self.negative_samples.append((transformed_img, 0))\n",
    "\n",
    "    def __len__(self):\n",
    "        # Dataset reports a fixed length, matching the configured sample budget.\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Randomly pick from positive or negative pools for rough 50/50 balance.\n",
    "        if random.random() < 0.5:\n",
    "            # Map any index to the available positive pool size\n",
    "            idx = index % len(self.positive_samples)\n",
    "            img, target = self.positive_samples[idx]\n",
    "        else:\n",
    "            # Map any index to the available negative pool size\n",
    "            idx = index % len(self.negative_samples)\n",
    "            img, target = self.negative_samples[idx]\n",
    "\n",
    "        # Return the tensor image and its label in a dict (common pattern for PyTorch Datasets)\n",
    "        return {\n",
    "            'image': img,\n",
    "            'target': target\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ac1ed0",
   "metadata": {},
   "source": [
    "This dataset balances classes by oversampling positives with multiple augmentations and using a shuffled subset of negatives. Transforms are applied during dataset creation, so the same augmented images are used each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cae435e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>sex</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>image_type</th>\n",
       "      <th>tbp_tile_type</th>\n",
       "      <th>tbp_lv_A</th>\n",
       "      <th>...</th>\n",
       "      <th>iddx_full</th>\n",
       "      <th>iddx_1</th>\n",
       "      <th>iddx_2</th>\n",
       "      <th>iddx_3</th>\n",
       "      <th>iddx_4</th>\n",
       "      <th>iddx_5</th>\n",
       "      <th>mel_mitotic_index</th>\n",
       "      <th>mel_thick_mm</th>\n",
       "      <th>tbp_lv_dnn_lesion_confidence</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015670</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_1235828</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>3.04</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>20.244422</td>\n",
       "      <td>...</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.517282</td>\n",
       "      <td>/Users/Yashwanth/isic/train-image/image/ISIC_0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015845</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_8170065</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>1.10</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>31.712570</td>\n",
       "      <td>...</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.141455</td>\n",
       "      <td>/Users/Yashwanth/isic/train-image/image/ISIC_0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015864</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_6724798</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>3.40</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>22.575830</td>\n",
       "      <td>...</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.804040</td>\n",
       "      <td>/Users/Yashwanth/isic/train-image/image/ISIC_0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0015902</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_4111386</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>3.22</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>14.242329</td>\n",
       "      <td>...</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.989998</td>\n",
       "      <td>/Users/Yashwanth/isic/train-image/image/ISIC_0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0024200</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_8313778</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>2.73</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>24.725520</td>\n",
       "      <td>...</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.442510</td>\n",
       "      <td>/Users/Yashwanth/isic/train-image/image/ISIC_0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401054</th>\n",
       "      <td>ISIC_9999937</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_1140263</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>6.80</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>22.574335</td>\n",
       "      <td>...</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.999988</td>\n",
       "      <td>/Users/Yashwanth/isic/train-image/image/ISIC_9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401055</th>\n",
       "      <td>ISIC_9999951</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_5678181</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>3.11</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>19.977640</td>\n",
       "      <td>...</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.999820</td>\n",
       "      <td>/Users/Yashwanth/isic/train-image/image/ISIC_9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401056</th>\n",
       "      <td>ISIC_9999960</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_0076153</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>2.05</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>17.332567</td>\n",
       "      <td>...</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.999416</td>\n",
       "      <td>/Users/Yashwanth/isic/train-image/image/ISIC_9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401057</th>\n",
       "      <td>ISIC_9999964</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_5231513</td>\n",
       "      <td>30.0</td>\n",
       "      <td>female</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>2.80</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>22.288570</td>\n",
       "      <td>...</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>/Users/Yashwanth/isic/train-image/image/ISIC_9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401058</th>\n",
       "      <td>ISIC_9999967</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_6426047</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>3.30</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>16.792900</td>\n",
       "      <td>...</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.999960</td>\n",
       "      <td>/Users/Yashwanth/isic/train-image/image/ISIC_9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401059 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             isic_id  target  patient_id  age_approx     sex  \\\n",
       "0       ISIC_0015670       0  IP_1235828        60.0    male   \n",
       "1       ISIC_0015845       0  IP_8170065        60.0    male   \n",
       "2       ISIC_0015864       0  IP_6724798        60.0    male   \n",
       "3       ISIC_0015902       0  IP_4111386        65.0    male   \n",
       "4       ISIC_0024200       0  IP_8313778        55.0    male   \n",
       "...              ...     ...         ...         ...     ...   \n",
       "401054  ISIC_9999937       0  IP_1140263        70.0    male   \n",
       "401055  ISIC_9999951       0  IP_5678181        60.0    male   \n",
       "401056  ISIC_9999960       0  IP_0076153        65.0  female   \n",
       "401057  ISIC_9999964       0  IP_5231513        30.0  female   \n",
       "401058  ISIC_9999967       0  IP_6426047        50.0    male   \n",
       "\n",
       "       anatom_site_general  clin_size_long_diam_mm          image_type  \\\n",
       "0          lower extremity                    3.04  TBP tile: close-up   \n",
       "1                head/neck                    1.10  TBP tile: close-up   \n",
       "2          posterior torso                    3.40  TBP tile: close-up   \n",
       "3           anterior torso                    3.22  TBP tile: close-up   \n",
       "4           anterior torso                    2.73  TBP tile: close-up   \n",
       "...                    ...                     ...                 ...   \n",
       "401054      anterior torso                    6.80  TBP tile: close-up   \n",
       "401055     posterior torso                    3.11  TBP tile: close-up   \n",
       "401056      anterior torso                    2.05  TBP tile: close-up   \n",
       "401057      anterior torso                    2.80  TBP tile: close-up   \n",
       "401058     lower extremity                    3.30  TBP tile: close-up   \n",
       "\n",
       "       tbp_tile_type   tbp_lv_A  ...  iddx_full  iddx_1  iddx_2  iddx_3  \\\n",
       "0          3D: white  20.244422  ...     Benign  Benign     NaN     NaN   \n",
       "1          3D: white  31.712570  ...     Benign  Benign     NaN     NaN   \n",
       "2             3D: XP  22.575830  ...     Benign  Benign     NaN     NaN   \n",
       "3             3D: XP  14.242329  ...     Benign  Benign     NaN     NaN   \n",
       "4          3D: white  24.725520  ...     Benign  Benign     NaN     NaN   \n",
       "...              ...        ...  ...        ...     ...     ...     ...   \n",
       "401054        3D: XP  22.574335  ...     Benign  Benign     NaN     NaN   \n",
       "401055     3D: white  19.977640  ...     Benign  Benign     NaN     NaN   \n",
       "401056        3D: XP  17.332567  ...     Benign  Benign     NaN     NaN   \n",
       "401057        3D: XP  22.288570  ...     Benign  Benign     NaN     NaN   \n",
       "401058        3D: XP  16.792900  ...     Benign  Benign     NaN     NaN   \n",
       "\n",
       "        iddx_4  iddx_5  mel_mitotic_index  mel_thick_mm  \\\n",
       "0          NaN     NaN                NaN           NaN   \n",
       "1          NaN     NaN                NaN           NaN   \n",
       "2          NaN     NaN                NaN           NaN   \n",
       "3          NaN     NaN                NaN           NaN   \n",
       "4          NaN     NaN                NaN           NaN   \n",
       "...        ...     ...                ...           ...   \n",
       "401054     NaN     NaN                NaN           NaN   \n",
       "401055     NaN     NaN                NaN           NaN   \n",
       "401056     NaN     NaN                NaN           NaN   \n",
       "401057     NaN     NaN                NaN           NaN   \n",
       "401058     NaN     NaN                NaN           NaN   \n",
       "\n",
       "        tbp_lv_dnn_lesion_confidence  \\\n",
       "0                          97.517282   \n",
       "1                           3.141455   \n",
       "2                          99.804040   \n",
       "3                          99.989998   \n",
       "4                          70.442510   \n",
       "...                              ...   \n",
       "401054                     99.999988   \n",
       "401055                     99.999820   \n",
       "401056                     99.999416   \n",
       "401057                    100.000000   \n",
       "401058                     99.999960   \n",
       "\n",
       "                                               image_path  \n",
       "0       /Users/Yashwanth/isic/train-image/image/ISIC_0...  \n",
       "1       /Users/Yashwanth/isic/train-image/image/ISIC_0...  \n",
       "2       /Users/Yashwanth/isic/train-image/image/ISIC_0...  \n",
       "3       /Users/Yashwanth/isic/train-image/image/ISIC_0...  \n",
       "4       /Users/Yashwanth/isic/train-image/image/ISIC_0...  \n",
       "...                                                   ...  \n",
       "401054  /Users/Yashwanth/isic/train-image/image/ISIC_9...  \n",
       "401055  /Users/Yashwanth/isic/train-image/image/ISIC_9...  \n",
       "401056  /Users/Yashwanth/isic/train-image/image/ISIC_9...  \n",
       "401057  /Users/Yashwanth/isic/train-image/image/ISIC_9...  \n",
       "401058  /Users/Yashwanth/isic/train-image/image/ISIC_9...  \n",
       "\n",
       "[401059 rows x 56 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e2a1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = ISICDataset(df, phase = \"train\", transforms=data_transforms[\"train\"])\n",
    "#valid_dataset = ISICDataset(df, phase = \"validation\", transforms=data_transforms[\"validation\"])\n",
    "train_dataset = ISICDataset(df, phase = \"train\", transforms=data_transforms[\"train_testing\"])\n",
    "valid_dataset = ISICDataset(df, phase = \"validation\", transforms=data_transforms[\"train_testing\"])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                          num_workers=3, shuffle=True, pin_memory=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                          num_workers=3, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76882491",
   "metadata": {},
   "source": [
    "This block prepares training and validation datasets with the chosen augmentation set, then wraps them in DataLoaders for batching and efficient loading during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67c9e1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0.0    80214\n",
       "1.0    80212\n",
       "2.0    80211\n",
       "3.0    80211\n",
       "4.0    80211\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>sex</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>image_type</th>\n",
       "      <th>tbp_tile_type</th>\n",
       "      <th>tbp_lv_A</th>\n",
       "      <th>...</th>\n",
       "      <th>iddx_full</th>\n",
       "      <th>iddx_1</th>\n",
       "      <th>iddx_2</th>\n",
       "      <th>iddx_3</th>\n",
       "      <th>iddx_4</th>\n",
       "      <th>iddx_5</th>\n",
       "      <th>mel_mitotic_index</th>\n",
       "      <th>mel_thick_mm</th>\n",
       "      <th>tbp_lv_dnn_lesion_confidence</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015670</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_1235828</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>3.04</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>20.244422</td>\n",
       "      <td>...</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.517282</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015845</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_8170065</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>1.10</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>31.712570</td>\n",
       "      <td>...</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.141455</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015864</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_6724798</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>3.40</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>22.575830</td>\n",
       "      <td>...</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.804040</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0015902</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_4111386</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>3.22</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>14.242329</td>\n",
       "      <td>...</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.989998</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0024200</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_8313778</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>2.73</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>24.725520</td>\n",
       "      <td>...</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.442510</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id  target  patient_id  age_approx   sex anatom_site_general  \\\n",
       "0  ISIC_0015670       0  IP_1235828        60.0  male     lower extremity   \n",
       "1  ISIC_0015845       0  IP_8170065        60.0  male           head/neck   \n",
       "2  ISIC_0015864       0  IP_6724798        60.0  male     posterior torso   \n",
       "3  ISIC_0015902       0  IP_4111386        65.0  male      anterior torso   \n",
       "4  ISIC_0024200       0  IP_8313778        55.0  male      anterior torso   \n",
       "\n",
       "   clin_size_long_diam_mm          image_type tbp_tile_type   tbp_lv_A  ...  \\\n",
       "0                    3.04  TBP tile: close-up     3D: white  20.244422  ...   \n",
       "1                    1.10  TBP tile: close-up     3D: white  31.712570  ...   \n",
       "2                    3.40  TBP tile: close-up        3D: XP  22.575830  ...   \n",
       "3                    3.22  TBP tile: close-up        3D: XP  14.242329  ...   \n",
       "4                    2.73  TBP tile: close-up     3D: white  24.725520  ...   \n",
       "\n",
       "   iddx_full  iddx_1  iddx_2  iddx_3  iddx_4  iddx_5  mel_mitotic_index  \\\n",
       "0     Benign  Benign     NaN     NaN     NaN     NaN                NaN   \n",
       "1     Benign  Benign     NaN     NaN     NaN     NaN                NaN   \n",
       "2     Benign  Benign     NaN     NaN     NaN     NaN                NaN   \n",
       "3     Benign  Benign     NaN     NaN     NaN     NaN                NaN   \n",
       "4     Benign  Benign     NaN     NaN     NaN     NaN                NaN   \n",
       "\n",
       "   mel_thick_mm  tbp_lv_dnn_lesion_confidence  fold  \n",
       "0           NaN                     97.517282   3.0  \n",
       "1           NaN                      3.141455   1.0  \n",
       "2           NaN                     99.804040   4.0  \n",
       "3           NaN                     99.989998   1.0  \n",
       "4           NaN                     70.442510   0.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "gkf = GroupKFold(n_splits=CONFIG['n_fold'])\n",
    "for fold, (train_index, valid_index) in enumerate(gkf.split(train_df, train_df.target, train_df.patient_id)):\n",
    "    train_df.loc[valid_index, \"fold\"] = int(fold)\n",
    "    \n",
    "display(train_df.groupby('fold').size()), \n",
    "display(train_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d3e524",
   "metadata": {},
   "source": [
    " Splits the dataset into multiple folds for cross-validation, ensuring no patient overlap between train and validation within the same fold. It also labels each sample with its fold number for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "364b53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "#dataset = load_dataset(\"huggingface/cats-image\")\n",
    "#image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "#inputs = processor(image, return_tensors=\"pt\")\n",
    "\n",
    "#with torch.no_grad():\n",
    "#    logits = model(**inputs).logits\n",
    "\n",
    "## model predicts one of the 1000 ImageNet classes\n",
    "#predicted_label = logits.argmax(-1).item()\n",
    "#print(model.config.id2label[predicted_label])\n",
    "new_classifier = nn.Sequential(\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    nn.Linear(in_features=2048, out_features=2, bias=True),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Replace the old classifier with the new one\n",
    "model.classifier = new_classifier\n",
    "\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False\n",
    "\n",
    "    \n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Verify which parameters require gradients\n",
    "#for name, param in model.named_parameters():\n",
    "#    print(name, param.requires_grad)\n",
    "\n",
    "BEST_WEIGHT = r\"C:\\path\\to\\your\\weights\\v2_AUROC0.9324_Loss0.0043_epoch22_lossauroc.pth\"\n",
    "model.to(CONFIG['device']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf898db",
   "metadata": {},
   "source": [
    "This part loads pre-trained weights into the modified ResNet model. If the file path in BEST_WEIGHT is wrong or the file is missing, PyTorch will raise FileNotFoundError. Ensure BEST_WEIGHT points to the correct .pth file before calling torch.load()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1035c0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "def criterion(submission, solution, min_tpr: float = 0.80) -> float:\n",
    "    # Use only the probability/score for the positive class (index 1)\n",
    "    submission = submission[:, 1]\n",
    "    solution = solution[:, 1]\n",
    "    \n",
    "    # Print shapes for quick debugging\n",
    "    print(submission.shape, solution.shape)\n",
    "    \n",
    "    '''\n",
    "    # --- Partial AUC version (commented out) ---\n",
    "    # Convert ground truth to match negative-class metric style\n",
    "    v_gt = abs(solution - 1)\n",
    "    # Predict negative-class probability\n",
    "    v_pred = np.array([1.0 - x for x in submission])\n",
    "    # Calculate partial AUC up to a given false positive rate\n",
    "    max_fpr = abs(1 - min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    # Rescale the partial AUC score to a different numeric range\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return partial_auc\n",
    "    '''\n",
    "    \n",
    "    # --- Focal loss version (active) ---\n",
    "    gamma = 2\n",
    "    alpha = 0.8\n",
    "\n",
    "    # Binary Cross-Entropy loss\n",
    "    BCE = F.binary_cross_entropy(submission, solution, reduction='mean')\n",
    "    # Exponential term used in focal loss calculation\n",
    "    BCE_EXP = torch.exp(-BCE)\n",
    "    # Apply focal loss formula to give more weight to hard examples\n",
    "    focal_loss = alpha * (1 - BCE_EXP) ** gamma * BCE\n",
    "\n",
    "    return focal_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb30b99",
   "metadata": {},
   "source": [
    "This function defines a custom loss. The active part uses focal loss to focus training on harder examples by down-weighting easy ones. A commented-out alternative computes a partial AUC metric for evaluation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc57c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "773083c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    device = CONFIG[\"device\"]\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_auroc = 0.0\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        print(step)  # Debug: show current step\n",
    "\n",
    "        # Move data to device\n",
    "        images = batch['image'].to(device, dtype=torch.float)\n",
    "        targets = batch['target'].to(device, dtype=torch.int64)  # Class indices\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Preprocess images using the model's processor\n",
    "        inputs = processor(images, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # Forward pass (no torch.no_grad in training)\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "        # Compute loss (convert targets to one-hot for criterion)\n",
    "        loss = criterion(\n",
    "            logits,\n",
    "            torch.nn.functional.one_hot(targets, num_classes=2) * 1.0\n",
    "        )\n",
    "        # Gradient accumulation\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "\n",
    "        print(loss)  # Debug: show loss\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer step every n_accumulate steps\n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "        # Calculate AUROC using predicted class indices\n",
    "        predicted_label = torch.argmax(logits, dim=-1)\n",
    "        auroc = binary_auroc(input=predicted_label, target=targets).item()\n",
    "\n",
    "        # Track total loss and AUROC\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        running_auroc += (auroc * batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        # Compute average loss and AUROC so far\n",
    "        train_epoch_loss = running_loss / dataset_size\n",
    "        train_epoch_auroc = running_auroc / dataset_size\n",
    "\n",
    "    gc.collect()  # Free up unused memory\n",
    "\n",
    "    return train_epoch_loss, train_epoch_auroc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fc0191",
   "metadata": {},
   "source": [
    "This function trains the model for one epoch. It processes batches, computes loss, updates weights (with optional gradient accumulation), and tracks average loss and AUROC score for the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ef37f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_auroc = 0.0\n",
    "    \n",
    "    for batch in valid_loader:\n",
    "        # Move data to the correct device\n",
    "        images = batch['image'].to(device, dtype=torch.float)\n",
    "        targets = batch['target'].to(device, dtype=torch.int64)  # Class indices\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Preprocess images using the model's processor\n",
    "        inputs = processor(images, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # Forward pass to get logits\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "        # Compute loss (convert targets to one-hot for criterion)\n",
    "        loss = criterion(\n",
    "            logits,\n",
    "            torch.nn.functional.one_hot(targets, num_classes=2) * 1.0\n",
    "        )\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "\n",
    "        print(loss)  # Debug: print batch loss\n",
    "\n",
    "        # Get predicted class labels\n",
    "        predicted_label = torch.argmax(logits, dim=-1)\n",
    "        auroc = binary_auroc(input=predicted_label, target=targets).item()\n",
    "\n",
    "        # Accumulate total loss and AUROC\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        running_auroc += (auroc * batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        # Compute average loss and AUROC so far\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        epoch_auroc = running_auroc / dataset_size\n",
    "      \n",
    "    gc.collect()  # Clean up unused memory\n",
    "    \n",
    "    return epoch_loss, epoch_auroc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910592c8",
   "metadata": {},
   "source": [
    "This function evaluates the model for one epoch without gradient updates. It calculates average loss and AUROC across the validation set to measure performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bafebf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA (GPU support) is available and print the GPU name\n",
    "if torch.cuda.is_available():\n",
    "    print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7336ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    # Select and return a learning rate scheduler based on CONFIG\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=CONFIG['T_max'],   # Number of iterations for one cycle\n",
    "            eta_min=CONFIG['min_lr'] # Minimum learning rate\n",
    "        )\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer,\n",
    "            T_0=CONFIG['T_0'],       # Iterations before first restart\n",
    "            eta_min=CONFIG['min_lr'] # Minimum learning rate\n",
    "        )\n",
    "    elif CONFIG['scheduler'] is None:\n",
    "        return None  # No scheduler\n",
    "    \n",
    "    return scheduler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d76da",
   "metadata": {},
   "source": [
    "Chooses and returns a learning rate scheduler based on configuration. Supports Cosine Annealing and Cosine Annealing with Warm Restarts, or returns None if no scheduler is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4546921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set PyTorch to use the GPU (CUDA) device\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7139afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Adam optimizer with learning rate and weight decay from CONFIG\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Get the learning rate scheduler based on CONFIG settings\n",
    "scheduler = fetch_scheduler(optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6cc07f",
   "metadata": {},
   "source": [
    "Initializes the Adam optimizer for model training and retrieves the appropriate learning rate scheduler according to the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f8162ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the start time of training\n",
    "start = time.time()\n",
    "\n",
    "# Save an initial copy of the model's weights (best model tracking)\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# Initialize best AUROC score as negative infinity\n",
    "best_epoch_auroc = -np.inf\n",
    "\n",
    "# Dictionary to log training history for later analysis\n",
    "history = {\n",
    "    \"Train Loss\": [],\n",
    "    \"Valid Loss\": [],\n",
    "    \"Train AUROC\": [],\n",
    "    \"Valid AUROC\": [],\n",
    "    \"lr\": []  # Learning rate history\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d92575c",
   "metadata": {},
   "source": [
    "Starts a timer, stores an initial copy of model weights, sets a baseline best AUROC, and prepares a dictionary to track loss, AUROC, and learning rate during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14be71e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yashwanth\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "\n",
    "    #start = time.time()\n",
    "    #best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    #best_epoch_auroc = -np.inf\n",
    "    #history = {\"Train Loss\": [], \"Valid Loss\": [], 'Train AUROC': [], 'Valid AUROC' : [], 'lr' : []}\n",
    "    \n",
    "    for epoch in range(13,13+CONFIG['epochs']): \n",
    "        gc.collect()\n",
    "        train_epoch_loss, train_epoch_auroc = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG['device'], epoch=epoch)\n",
    "        \n",
    "        val_epoch_loss, val_epoch_auroc = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
    "                                         epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "        history['Train AUROC'].append(train_epoch_auroc)\n",
    "        history['Valid AUROC'].append(val_epoch_auroc)\n",
    "        history['lr'].append( scheduler.get_lr()[0] )\n",
    "        \n",
    "        print(history)\n",
    "        # deep copy the model\n",
    "        if 2>1:# best_epoch_auroc <= val_epoch_auroc:\n",
    "            print(f\"Validation AUROC Improved ({best_epoch_auroc} ---> {val_epoch_auroc})\")\n",
    "            best_epoch_auroc = val_epoch_auroc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = \"/home/mccruz/isic/ISIC2024_Skin_Cancer_Detection/v2_AUROC{:.4f}_Loss{:.4f}_epoch{:.0f}_lossauroc.pth\".format(val_epoch_auroc, val_epoch_loss, epoch)\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved\")\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best AUROC: {:.4f}\".format(best_epoch_auroc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
